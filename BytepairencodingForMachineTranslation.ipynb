{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bytepairencoding seq2seq model in keras that translates english <-> german"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step I take the model used for the [toy problem of adding/subtracting numbers](SimpleModelForAddingAndSubstraction.ipynb) and train it with english/german data for machine translation.\n",
    "\n",
    "As trainings set I use the [European Parliament Proceedings Parallel Corpus 1996-2011](http://statmt.org/europarl/) German-English corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:11.251741Z",
     "start_time": "2018-05-10T14:06:09.956634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# technical detail so that an instance (maybe running in a different window)\n",
    "# doesn't take all the GPU memory resulting in some strange error messages\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:11.618574Z",
     "start_time": "2018-05-10T14:06:11.253097Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Fixing random state ensure reproducible results\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:11.622216Z",
     "start_time": "2018-05-10T14:06:11.619825Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '\\n'\n",
    "\n",
    "MAX_INPUT_LENGTH = 25 #50\n",
    "MAX_TARGET_LENGTH = 35 #65\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 100\n",
    "BPE_MERGE_OPERATIONS = 1000\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "DROPOUT = 0.5\n",
    "TEST_SIZE=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T13:03:31.674082Z",
     "start_time": "2018-05-08T13:03:31.670919Z"
    }
   },
   "source": [
    "## Download and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:11.631771Z",
     "start_time": "2018-05-10T14:06:11.623613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-en.tgz already downloaded (188.6 MB)\n",
      "en.wiki.bpe.op1000.model already downloaded (0.2 MB)\n",
      "en.wiki.bpe.op1000.d100.w2v.bin.tar.gz already downloaded (0.7 MB)\n"
     ]
    }
   ],
   "source": [
    "def download_file(fname, url):\n",
    "    print(f\"Downloading {fname} from {url} ...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    total_size = int(response.headers.get('content-length', 0)); \n",
    "    block_size = 1024\n",
    "\n",
    "    download = tqdm(\n",
    "        response.iter_content(block_size),\n",
    "        total=math.ceil(total_size // block_size),\n",
    "        unit='KB',\n",
    "        unit_scale=True\n",
    "    )\n",
    "    with open(f\"{fname}\", \"wb\") as handle:\n",
    "        for data in download:\n",
    "            handle.write(data)\n",
    "\n",
    "PATH = 'data'\n",
    "BPE_URL = 'http://cosyne.h-its.org/bpemb/data/en/'\n",
    "BPE_FNAME_MODEL = f'en.wiki.bpe.op{BPE_MERGE_OPERATIONS}.model'\n",
    "BPE_FNAME_WORD2VEC = f'en.wiki.bpe.op{BPE_MERGE_OPERATIONS}.d{EMBEDDING_DIM}.w2v.bin'\n",
    "DOWNLOAD_FILES = {\n",
    "    'de-en.tgz': 'http://statmt.org/europarl/v7/de-en.tgz',\n",
    "    BPE_FNAME_MODEL: f'{BPE_URL}/{BPE_FNAME_MODEL}',\n",
    "    BPE_FNAME_WORD2VEC + '.tar.gz': f'{BPE_URL}/{BPE_FNAME_WORD2VEC}' + '.tar.gz',\n",
    "}\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "\n",
    "for name, url in DOWNLOAD_FILES.items():\n",
    "    fname = os.path.join(PATH, name)\n",
    "    exists = os.path.exists(fname)\n",
    "    size = os.path.getsize(fname) if exists else -1\n",
    "    if exists and size > 0:\n",
    "        print(f'{name} already downloaded ({size / 2**20:3.1f} MB)')\n",
    "        continue\n",
    "    download_file(fname, url)\n",
    "    if (re.search(r'\\.(tgz|tar\\.gz)$', fname)):\n",
    "        tar = tarfile.open(fname, \"r:gz\")\n",
    "        tar.extractall(path=PATH)\n",
    "        tar.close()\n",
    "        print(f'Extracted {fname} ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:58.623116Z",
     "start_time": "2018-05-10T14:06:11.633318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Following https://github.com/bheinzerling/bpemb/blob/master/preprocess_text.sh\n",
    "# (ignoring urls as there shouldn't be any in parliament discussions)\n",
    "def preprocess(line):\n",
    "    line = re.sub(r'\\d+', '0', line)\n",
    "    line = re.sub(r'\\s+', ' ', line)  # keep newlines, but strip together all other whitespaces\n",
    "    return line.lower().strip()\n",
    "\n",
    "def read_corpus_lines(language):\n",
    "    return [preprocess(line) for line in open(f'{PATH}/europarl-v7.de-en.{language}', 'r').readlines()]\n",
    "    \n",
    "pd.set_option('max_colwidth', 60)\n",
    "df = pd.DataFrame(data={\n",
    "    'input_texts': read_corpus_lines('en'),\n",
    "    'target_texts': read_corpus_lines('de'), \n",
    "})\n",
    "df.target_texts = START + df.target_texts + END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:06:59.583790Z",
     "start_time": "2018-05-10T14:06:58.625541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920209"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>input_length</th>\n",
       "      <th>target_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resumption of the session</td>\n",
       "      <td>^wiederaufnahme der sitzungsperiode\\n</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i declare resumed the session of the european parliament...</td>\n",
       "      <td>^ich erkläre die am freitag, dem 0. dezember unterbroche...</td>\n",
       "      <td>203</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>although, as you will have seen, the dreaded 'millennium...</td>\n",
       "      <td>^wie sie feststellen konnten, ist der gefürchtete \"mille...</td>\n",
       "      <td>191</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have requested a debate on this subject in the cours...</td>\n",
       "      <td>^im parlament besteht der wunsch nach einer aussprache i...</td>\n",
       "      <td>105</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the meantime, i should like to observe a minute' s si...</td>\n",
       "      <td>^heute möchte ich sie bitten - das ist auch der wunsch e...</td>\n",
       "      <td>232</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input_texts  \\\n",
       "0                                    resumption of the session   \n",
       "1  i declare resumed the session of the european parliament...   \n",
       "2  although, as you will have seen, the dreaded 'millennium...   \n",
       "3  you have requested a debate on this subject in the cours...   \n",
       "4  in the meantime, i should like to observe a minute' s si...   \n",
       "\n",
       "                                                  target_texts  input_length  \\\n",
       "0                        ^wiederaufnahme der sitzungsperiode\\n            25   \n",
       "1  ^ich erkläre die am freitag, dem 0. dezember unterbroche...           203   \n",
       "2  ^wie sie feststellen konnten, ist der gefürchtete \"mille...           191   \n",
       "3  ^im parlament besteht der wunsch nach einer aussprache i...           105   \n",
       "4  ^heute möchte ich sie bitten - das ist auch der wunsch e...           232   \n",
       "\n",
       "   target_length  \n",
       "0             36  \n",
       "1            219  \n",
       "2            187  \n",
       "3            112  \n",
       "4            219  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "df.target_texts = df.target_texts  # encode a start symbol (doesn't occur in texts)\n",
    "df['input_length'] = df.input_texts.apply(len)\n",
    "df['target_length'] = df.target_texts.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.073679Z",
     "start_time": "2018-05-10T14:06:59.585431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df.input_length\n",
    "logbins = np.logspace(1,5,20)\n",
    "plt.hist(x, bins=logbins)\n",
    "plt.xscale('log')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.169212Z",
     "start_time": "2018-05-10T14:07:00.075230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42656"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty = (df.input_length > 1) & (df.target_length > 1)  # there are empty phrases like '\\n' --> 'Frau Präsidentin\\n'\n",
    "short_inputs = (df.input_length < MAX_INPUT_LENGTH) & (df.target_length < MAX_TARGET_LENGTH)\n",
    "sum(short_inputs)\n",
    "df = df[non_empty & short_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.194955Z",
     "start_time": "2018-05-10T14:07:00.170919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁this', '▁is', '▁a', '▁t', 'est']\n"
     ]
    }
   ],
   "source": [
    "input_pretrained_bpe = KeyedVectors.load_word2vec_format(os.path.join(PATH, BPE_FNAME_WORD2VEC), binary=True)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(os.path.join(PATH, BPE_FNAME_MODEL))\n",
    "subwords = sp.EncodeAsPieces(\"this is a test\")\n",
    "print(subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.603939Z",
     "start_time": "2018-05-10T14:07:00.196865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "input_wordvec_index = dict({\n",
    "    word: index \n",
    "    for index, word \n",
    "    in enumerate(['<pad>', '<s>', '</s>'] + input_pretrained_bpe.wv.index2word)  # haven't found start/stop tokens, so add them manually\n",
    "})\n",
    "input_unk_index = input_wordvec_index['<unk>']\n",
    "\n",
    "def subword_indices(text, unk_index=input_unk_index, wordvec_index=input_wordvec_index):\n",
    "    subwords = ['<s>'] + sp.EncodeAsPieces(text) + ['</s>']  # automatic add start/stop index\n",
    "    return [wordvec_index.get(subword, unk_index) for subword in subwords]\n",
    "\n",
    "FULL_EMBEDDING_DIM = EMBEDDING_DIM + 2\n",
    "input_embedding_matrix = np.zeros((len(input_wordvec_index), FULL_EMBEDDING_DIM))\n",
    "input_embedding_matrix[0, :] = 1e-6 * np.random.standard_normal(FULL_EMBEDDING_DIM)  # pad symbol as close to zero\n",
    "input_embedding_matrix[1, -1] = 1  # one hot encode start symbol\n",
    "input_embedding_matrix[2, -2] = 1  # one hot encode stop symbol\n",
    "input_embedding_matrix[3:, :-2] = input_pretrained_bpe.wv.vectors\n",
    "\n",
    "df['input_sequences'] = df.input_texts.apply(subword_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.609582Z",
     "start_time": "2018-05-10T14:07:00.605787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.92108153e-07, -1.46351495e-06,  2.96120277e-07,\n",
       "         2.61055272e-07,  5.11345664e-09, -2.34587133e-07,\n",
       "        -1.41537074e-06, -4.20645323e-07],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00],\n",
       "       [-1.54319003e-01,  1.55878007e-01,  5.60858011e-01,\n",
       "        -1.23772003e-01,  1.91783994e-01,  3.10420003e-02,\n",
       "         0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding_matrix[:4, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.614862Z",
     "start_time": "2018-05-10T14:07:00.611217Z"
    }
   },
   "outputs": [],
   "source": [
    "# corpus = pd.concat([df.input_texts, df.target_texts])\n",
    "corpus = df.target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.985019Z",
     "start_time": "2018-05-10T14:07:00.616532Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=100, filters=None, char_level=True, oov_token='~')\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "# df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:00.993291Z",
     "start_time": "2018-05-10T14:07:00.986409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 77009),\n",
       " (' ', 71426),\n",
       " ('s', 58523),\n",
       " ('i', 52429),\n",
       " ('n', 43297),\n",
       " ('a', 41079),\n",
       " ('r', 33786),\n",
       " ('\\n', 33394),\n",
       " ('^', 33394),\n",
       " ('t', 32240),\n",
       " ('h', 29154),\n",
       " ('l', 25435),\n",
       " ('d', 24917),\n",
       " ('c', 21775),\n",
       " ('u', 18599),\n",
       " ('.', 18088),\n",
       " ('g', 16447),\n",
       " ('o', 13467),\n",
       " ('b', 12779),\n",
       " ('m', 12093),\n",
       " ('f', 9584),\n",
       " ('w', 9561),\n",
       " ('k', 7730),\n",
       " ('p', 7217),\n",
       " ('(', 4672),\n",
       " (')', 4577),\n",
       " ('z', 4228),\n",
       " ('v', 4121),\n",
       " ('?', 3672),\n",
       " ('0', 2919),\n",
       " ('!', 2480),\n",
       " ('ä', 2193),\n",
       " ('ü', 2144),\n",
       " (',', 2080),\n",
       " ('-', 1606),\n",
       " (':', 1099),\n",
       " ('ö', 1084),\n",
       " ('ß', 865),\n",
       " ('j', 736),\n",
       " ('/', 698),\n",
       " ('y', 305),\n",
       " ('\"', 161),\n",
       " ('x', 105),\n",
       " ('–', 64),\n",
       " ('q', 56),\n",
       " (\"'\", 35),\n",
       " ('%', 33),\n",
       " ('é', 31),\n",
       " ('á', 22),\n",
       " ('í', 15),\n",
       " ('°', 12),\n",
       " ('“', 12),\n",
       " ('è', 11),\n",
       " ('*', 9),\n",
       " ('ã', 7),\n",
       " ('„', 6),\n",
       " (';', 6),\n",
       " ('æ', 5),\n",
       " ('ó', 5),\n",
       " ('š', 4),\n",
       " ('à', 4),\n",
       " ('ç', 3),\n",
       " ('ń', 3),\n",
       " ('č', 3),\n",
       " ('å', 3),\n",
       " ('’', 3),\n",
       " ('ò', 3),\n",
       " ('´', 2),\n",
       " ('ñ', 2),\n",
       " ('α', 2),\n",
       " ('π', 2),\n",
       " (']', 2),\n",
       " ('[', 2),\n",
       " ('ň', 2),\n",
       " ('¡', 2),\n",
       " ('<', 2),\n",
       " ('о', 2),\n",
       " ('д', 2),\n",
       " ('…', 2),\n",
       " ('•', 2),\n",
       " ('ł', 2),\n",
       " ('ï', 2),\n",
       " ('ì', 1),\n",
       " ('ą', 1),\n",
       " ('ή', 1),\n",
       " ('χ', 1),\n",
       " ('ο', 1),\n",
       " ('ά', 1),\n",
       " ('τ', 1),\n",
       " ('κ', 1),\n",
       " ('ρ', 1),\n",
       " ('έ', 1),\n",
       " ('υ', 1),\n",
       " ('ž', 1),\n",
       " ('ǎ', 1),\n",
       " ('ő', 1),\n",
       " ('ý', 1),\n",
       " ('и', 1),\n",
       " ('л', 1),\n",
       " ('ш', 1),\n",
       " ('е', 1),\n",
       " ('р', 1),\n",
       " ('б', 1),\n",
       " ('ţ', 1),\n",
       " ('ę', 1),\n",
       " ('+', 1),\n",
       " ('û', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(sorted(tokenizer.word_counts.items(), key=lambda d: d[1])))\n",
    "sum(1 for w, count in tokenizer.word_counts.items() if count > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:01.014182Z",
     "start_time": "2018-05-10T14:07:00.994558Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len_input = df.input_sequences.apply(len).max()\n",
    "max_len_target = df.target_sequences.apply(len).max()\n",
    "nr_input_tokens = len(input_wordvec_index)  \n",
    "nr_target_tokens = len(tokenizer.word_index) + 1  # add 0 padding not in word_index contained\n",
    "\n",
    "# one hot encoded y_t_output wouldn't fit into memory any longer\n",
    "# so need to train/validate on batches generated on the fly\n",
    "def create_batch_generator(samples_ids):\n",
    "    \n",
    "    def batch_generator():\n",
    "        nr_batches = np.ceil(len(samples_ids) / BATCH_SIZE)\n",
    "        while True:\n",
    "            shuffled_ids = np.random.permutation(samples_ids)\n",
    "            batch_splits = np.array_split(shuffled_ids, nr_batches)\n",
    "            for batch_ids in batch_splits:\n",
    "                batch_X = pad_sequences(df.iloc[batch_ids].input_sequences, padding='post', maxlen=max_len_input)\n",
    "                batch_y = pad_sequences(df.iloc[batch_ids].target_sequences, padding='post', maxlen=max_len_target)\n",
    "                batch_y_t_output = keras.utils.to_categorical(batch_y[:,1:], num_classes=len(tokenizer.word_index)+1)\n",
    "                batch_x_t_input = batch_y[:,:-1]\n",
    "                yield ([batch_X, batch_x_t_input], batch_y_t_output)\n",
    "    \n",
    "    return batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:01.018512Z",
     "start_time": "2018-05-10T14:07:01.015634Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(np.arange(df.shape[0]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:01.026438Z",
     "start_time": "2018-05-10T14:07:01.019878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1832, 109)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30054, 3340)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_input_tokens, nr_target_tokens\n",
    "len(tokenizer.word_index)\n",
    "len(train_ids), len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:02.164293Z",
     "start_time": "2018-05-10T14:07:01.027873Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_gru = L.Bidirectional(\n",
    "    L.GRU(LATENT_DIM // 2, dropout=DROPOUT, return_state=True, name='encoder_gru'),\n",
    "    name='encoder_bidirectional'\n",
    ")\n",
    "decoder_gru = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, return_state=True, name='decoder_gru')\n",
    "decoder_dense = L.Dense(nr_target_tokens, activation='softmax', name='decoder_outputs')\n",
    "\n",
    "input_embedding = L.Embedding(\n",
    "    nr_input_tokens,\n",
    "    FULL_EMBEDDING_DIM,\n",
    "    mask_zero=True,\n",
    "    weights=[input_embedding_matrix],\n",
    "    name='input_embedding',\n",
    "    trainable=False\n",
    ")\n",
    "target_embedding = L.Embedding(nr_target_tokens, EMBEDDING_DIM, mask_zero=True, name='target_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = input_embedding(encoder_inputs)\n",
    "_, encoder_state_1, encoder_state_2 = encoder_gru(encoder_embeddings)\n",
    "encoder_states = L.concatenate([encoder_state_1, encoder_state_2])\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target-1, ), dtype='int32', name='decoder_inputs')\n",
    "decoder_mask = L.Masking(mask_value=0)(decoder_inputs)\n",
    "decoder_embeddings_inputs = target_embedding(decoder_mask)\n",
    "decoder_embeddings_outputs, _ = decoder_gru(decoder_embeddings_inputs, initial_state=encoder_states) \n",
    "decoder_outputs = decoder_dense(decoder_embeddings_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "inference_encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "inference_decoder_state_inputs = L.Input(shape=(LATENT_DIM, ), dtype='float32', name='inference_decoder_state_inputs')\n",
    "inference_decoder_embeddings_outputs, inference_decoder_states = decoder_gru(\n",
    "    decoder_embeddings_inputs, initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_outputs = decoder_dense(inference_decoder_embeddings_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_inputs, inference_decoder_state_inputs], \n",
    "    [inference_decoder_outputs, inference_decoder_states]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:02.169758Z",
     "start_time": "2018-05-10T14:07:02.165452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, 33)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_embedding (Embedding)     (None, 20, 102)      186864      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 33)           0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bidirectional (Bidirect [(None, 512), (None, 551424      input_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Embedding)    (None, 33, 100)      10900       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           encoder_bidirectional[0][1]      \n",
      "                                                                 encoder_bidirectional[0][2]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 33, 512), (N 941568      target_embedding[0][0]           \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 33, 109)      55917       decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,746,673\n",
      "Trainable params: 1,559,809\n",
      "Non-trainable params: 186,864\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 33)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 33)           0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "target_embedding (Embedding)    (None, 33, 100)      10900       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inference_decoder_state_inputs  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 33, 512), (N 941568      target_embedding[0][0]           \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 33, 109)      55917       decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,008,385\n",
      "Trainable params: 1,008,385\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "inference_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:07:02.209841Z",
     "start_time": "2018-05-10T14:07:02.171641Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=1.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:34.479647Z",
     "start_time": "2018-05-10T14:07:02.211240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 15s 63ms/step - loss: 1.9450 - val_loss: 1.1529\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 1.0224 - val_loss: 0.8535\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.8315 - val_loss: 0.7385\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.7283 - val_loss: 0.6761\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.6587 - val_loss: 0.6294\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.6078 - val_loss: 0.5687\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.5666 - val_loss: 0.5676\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.5335 - val_loss: 0.5432\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.5047 - val_loss: 0.5283\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.4801 - val_loss: 0.5335\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.4577 - val_loss: 0.5116\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.4381 - val_loss: 0.5079\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.4204 - val_loss: 0.5073\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 14s 57ms/step - loss: 0.4037 - val_loss: 0.5067\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.3885 - val_loss: 0.5044\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.3748 - val_loss: 0.4908\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.3624 - val_loss: 0.5069\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.3496 - val_loss: 0.5089\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 14s 58ms/step - loss: 0.3390 - val_loss: 0.5054\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 13s 57ms/step - loss: 0.3275 - val_loss: 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efa1519e630>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = create_batch_generator(train_ids)\n",
    "val_generator = create_batch_generator(val_ids)\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(len(train_ids) / BATCH_SIZE),\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=np.ceil(len(val_ids) / BATCH_SIZE),\n",
    ")\n",
    "#model.fit([X, x_t_input], y_t_output, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:34.491551Z",
     "start_time": "2018-05-10T14:11:34.483150Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, max_len_target-1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[START]\n",
    "    \n",
    "    tokens = {idx: token for (token, idx) in tokenizer.word_index.items()}\n",
    "    \n",
    "    decoded_sequence = ''\n",
    "    for i in range(max_len_target):\n",
    "        output_tokens, output_states = inference_decoder_model.predict(\n",
    "            [target_seq, states_value]\n",
    "        )\n",
    "        \n",
    "        # greedy search\n",
    "        sampled_token_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_token = tokens.get(sampled_token_idx, '.')\n",
    "        if sampled_token == END:\n",
    "            break\n",
    "        decoded_sequence += sampled_token\n",
    "            \n",
    "        target_seq[0, 0] = sampled_token_idx\n",
    "        states_value = output_states\n",
    "    \n",
    "    return decoded_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:34.498111Z",
     "start_time": "2018-05-10T14:11:34.494009Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    # print(sentence),\n",
    "    # print(preprocess(sentence))\n",
    "    # print(subword_indices(preprocess(sentence)))\n",
    "    return decode_sequence(keras.preprocessing.sequence.pad_sequences(\n",
    "        [subword_indices(preprocess(sentence))],\n",
    "        padding='post',\n",
    "        maxlen=max_len_input,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:36.976307Z",
     "start_time": "2018-05-10T14:11:34.499544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello.\\n' --> 'helfen.'\n",
      "'You are welcome.\\n' --> 'sie sind begrüßenswegt.'\n",
      "'How do you do?\\n' --> 'wie können sie uns das vermeinen?'\n",
      "'I hate mondays.\\n' --> 'ich habe das wort.'\n",
      "'I am a programmer.\\n' --> 'ich bin eine demokratie.'\n",
      "'Data is the new oil.\\n' --> 'die situation ist klar.'\n",
      "'It could be worse.\\n' --> 'das muss sehr getan werden.'\n",
      "'I am on top of it.\\n' --> 'ich bin dafür.'\n",
      "'N° Uno\\n' --> '0. orit'\n",
      "'Awesome!\\n' --> 'was für eine lösen!'\n",
      "'Put your feet up!\\n' --> 'passiert uns rein!'\n",
      "'From the start till the end!\\n' --> 'im gegenteil!'\n",
      "'From dusk till dawn.\\n' --> 'eine komle and kommensan.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on some examples:\n",
    "EXAMPLES = [\n",
    "    'Hello.',\n",
    "    'You are welcome.',\n",
    "    'How do you do?',\n",
    "    'I hate mondays.',\n",
    "    'I am a programmer.',\n",
    "    'Data is the new oil.',\n",
    "    'It could be worse.',\n",
    "    \"I am on top of it.\",\n",
    "    \"N° Uno\",\n",
    "    \"Awesome!\",\n",
    "    \"Put your feet up!\",\n",
    "    \"From the start till the end!\",\n",
    "    \"From dusk till dawn.\",\n",
    "]\n",
    "for en in [sentence + '\\n' for sentence in EXAMPLES]:\n",
    "    print(f\"{en!r} --> {predict(en)!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:40.422712Z",
     "start_time": "2018-05-10T14:11:36.977429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'relating to wednesday:', got 'zum mittwoch:', exp: 'zum mittwoch:\\n'\n",
      "Original 'that was the decision.', got 'das war das erste schritt.', exp: 'das war der beschluß.\\n'\n",
      "Original 'we have agreed to this.', got 'darüber müssen wir arbeiten.', exp: 'wir haben dem zugestimmt.\\n'\n",
      "Original 'it is not a lot to ask.', got 'es ist keine wahl.', exp: 'das ist nicht zuviel verlangt.\\n'\n",
      "Original 'thank you very much.', got 'vielen dank.', exp: 'vielen dank.\\n'\n",
      "Original 'that did not happen.', got 'das darf nicht geschehen.', exp: 'dazu kam es nicht.\\n'\n",
      "Original 'the debate is closed.', got 'die aussprache ist geschlossen.', exp: 'die aussprache ist geschlossen.\\n'\n",
      "Original 'the debate is closed.', got 'die aussprache ist geschlossen.', exp: 'die aussprache ist geschlossen.\\n'\n",
      "Original 'the debate is closed.', got 'die aussprache ist geschlossen.', exp: 'die aussprache ist geschlossen.\\n'\n",
      "Original 'what is the result?', got 'was ist die komplicht?', exp: 'was sind die folgen?\\n'\n",
      "Original 'the debate is closed.', got 'die aussprache ist geschlossen.', exp: 'die aussprache ist geschlossen.\\n'\n",
      "Original 'are there any comments?', got 'gibt es einwände?', exp: 'gibt es einwände?\\n'\n",
      "Original 'thank you very much.', got 'vielen dank.', exp: 'vielen dank!\\n'\n",
      "Original 'with what aim?', got 'und was bedeutet das?', exp: 'zu welchem zweck?\\n'\n",
      "Original 'this is not in question.', got 'das ist keine weitereid.', exp: 'das steht außer zweifel.\\n'\n",
      "Original 'we all agree on this.', got 'darin sind wir uns alle einig.', exp: 'das sehen wir alle ein.\\n'\n",
      "Original 'why?', got 'warum?', exp: 'wieso?\\n'\n",
      "Original 'no.', got 'nein.', exp: 'nein.\\n'\n",
      "Original 'i do not believe so.', got 'ich glaube nicht.', exp: 'ich glaube nicht daran.\\n'\n"
     ]
    }
   ],
   "source": [
    "# Performance on training set:\n",
    "for en, de in df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de[1:]!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:11:43.789368Z",
     "start_time": "2018-05-10T14:11:40.424201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'approval of the minutes', got 'genehmigung des protokolls', exp: 'genehmigung des protokolls\\n'\n",
      "Original 'what?', got 'was will ich hinaus?', exp: 'was tun sie?\\n'\n",
      "Original \"the answer is 'no'.\", got 'die antwort lautet: ja.', exp: 'die antwort ist \"nein\".\\n'\n",
      "Original 'thank you.', got 'vielen dank.', exp: 'ich danke ihnen!\\n'\n",
      "Original 'for goodness sake!', got 'uns zu leicht!', exp: 'bei gott!\\n'\n",
      "Original 'how will it be kept?', got 'wie werden sie ausgelistet?', exp: 'wie werden sie gespeichert?\\n'\n",
      "Original 'i will be brief.', got 'ich werde mich kurz fassen.', exp: '(en) ich werde mich kurz fassen.\\n'\n",
      "Original 'the debate is closed.', got 'die aussprache ist geschlossen.', exp: 'die aussprache ist geschlossen.\\n'\n",
      "Original 'chemicals strategy', got 'villeffführung von unternehmen', exp: 'chemikalienpolitik\\n'\n",
      "Original 'how?', got 'wie?', exp: 'wie?\\n'\n",
      "Original 'thank you.', got 'vielen dank.', exp: 'vielen dank.\\n'\n",
      "Original 'yes or no?', got 'ja oder nein?', exp: 'ja oder nein?\\n'\n",
      "Original 'this is a scandal.', got 'das ist eine tatsache.', exp: 'das ist ein skandal.\\n'\n",
      "Original 'that is the truth.', got 'das ist die wahl.', exp: 'so sieht die wirklichkeit aus.\\n'\n",
      "Original 'so what is to be done?', got 'was ist zu tun?', exp: 'was ist also zu tun?\\n'\n",
      "Original 'guinebertière report', got 'zum bericht ferrunzi (a0-0/0)', exp: 'zum bericht guinebertière\\n'\n",
      "Original 'i quote word for word.', got 'ich habe dafür gestimmt.', exp: 'ein wörtliches zitat.\\n'\n",
      "Original 'i do not know.', got 'ich weiß es nicht.', exp: 'ich weiß es wirklich nicht.\\n'\n",
      "Original 'and so it should be.', got 'und das muss sich ändern.', exp: 'und so soll es auch sein.\\n'\n"
     ]
    }
   ],
   "source": [
    "# Performance on validation set\n",
    "val_df = df.iloc[val_ids]\n",
    "for en, de in val_df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de[1:]!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:13:14.554354Z",
     "start_time": "2018-05-10T14:11:43.790700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4da42e70bb34b6ebc9aaa8a33807fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average bleu score: 0.42061559946277755\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "try:\n",
    "    from spacy.lang.de import German\n",
    "except ModuleNotFoundError:\n",
    "    spacy.cli.download('de')\n",
    "    from spacy.lang.de import German\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "parser = German()\n",
    "chencherry = SmoothingFunction()  # to handle short sequences, see also http://www.nltk.org/_modules/nltk/translate/bleu_score.html#SmoothingFunction.method3\n",
    "\n",
    "def remove_spaces_and_puncts(tokens):\n",
    "     return [token.orth_ for token in tokens if not (token.is_space or token.is_punct)]  \n",
    "\n",
    "bleu_scores = np.zeros(TEST_SIZE)\n",
    "nist_scores = np.zeros(TEST_SIZE)\n",
    "\n",
    "for i in tqdm(range(TEST_SIZE)):\n",
    "    pred_tokens = remove_spaces_and_puncts(parser(predict(df.iloc[i].input_texts)))\n",
    "    ref_tokens = remove_spaces_and_puncts(parser(df.iloc[i].target_texts[1:]))\n",
    "    bleu_scores[i] = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=chencherry.method3)\n",
    "    \n",
    "print(\"Average bleu score:\", bleu_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-10T14:13:14.557246Z",
     "start_time": "2018-05-10T14:13:14.555512Z"
    }
   },
   "outputs": [],
   "source": [
    "## Conclusion\n",
    "\n",
    "# It doesn't work perfect, but fine enough to show that seq2seq works in some way. I wouldn't be surprised if the mean average error is better than average human bias for calculating without any tools.\n",
    "# For improvements and further discussions I'll move to a real problem (translating) and main steps will be:\n",
    "# * Bytepairencoding/Word embeddings\n",
    "# * Beam Search\n",
    "# * Attention models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 301,
   "position": {
    "height": "40px",
    "left": "987px",
    "right": "23px",
    "top": "124px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
