## State of the art overview for seq2seq models

* for toy problems, machine translation, summaries and chat botting
* in Keras first, then maybe PyTorch / Tensorflow
* from ground up simple model adding more higher level approaches (bytepairencodings, beam search, attentions, ...) 

## Models step for step:

1. [Simple Model for adding and subtracting numbers end-to-end on chars](SimpleModelForAddingAndSubstraction.ipynb)
2. [Simple Model char-level end-to-end for Machine Translation](SimpleModelForMachineTranslation.ipynb)
3. [Bytepairencoding embeddings instead for Machine Translation](BytepairencodingForMachineTranslation.ipynb)
4. [Implementing BeamSearch model](BeamSearchForMachineTranslation.ipynb)
5. [BeamSearch model trained on a larger dataset](BeamSearchOnLargeDataset.ipynb)
