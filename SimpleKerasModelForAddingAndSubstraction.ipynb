{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:47.950632Z",
     "start_time": "2018-05-01T18:09:46.680953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:47.954577Z",
     "start_time": "2018-05-01T18:09:47.952036Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:47.965580Z",
     "start_time": "2018-05-01T18:09:47.956419Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '$'\n",
    "\n",
    "SIZE = 10_000\n",
    "LATENT_DIM = 128\n",
    "EMBEDDING_DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:47.972776Z",
     "start_time": "2018-05-01T18:09:47.967491Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_equations_df(size, min_value=0, max_value=9999, operations={'+': np.add, '-': np.subtract}):\n",
    "    df = pd.DataFrame()\n",
    "    df['a'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['b'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['op'] = np.random.choice(list(operations.keys()), size)\n",
    "    df['result'] = np.zeros(size, dtype='int')\n",
    "    for symbol, calc in operations.items():\n",
    "        df.loc[df.op == symbol, 'result'] = calc(df[df.op == symbol]['a'], df[df.op == symbol]['b'])\n",
    "        \n",
    "    df['input_texts'] = START + df.a.astype(str) + df.op + df.b.astype(str) + END\n",
    "    df['target_texts'] = START + df.result.astype(str) + END\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:48.018691Z",
     "start_time": "2018-05-01T18:09:47.974359Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_equations_df(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:48.023135Z",
     "start_time": "2018-05-01T18:09:48.020108Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.concat([df.input_texts, df.target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:48.142747Z",
     "start_time": "2018-05-01T18:09:48.024848Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters=None, char_level=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:00:34.613893Z",
     "start_time": "2018-05-01T19:00:34.522610Z"
    }
   },
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(df.input_sequences, padding='post')\n",
    "y = keras.preprocessing.sequence.pad_sequences(df.target_sequences, padding='post')\n",
    "# y_val = df.result.astype(np.float32)\n",
    "y_one_hot = keras.utils.to_categorical(y, num_classes=nr_tokens)\n",
    "\n",
    "max_len_input = X.shape[1]\n",
    "max_len_target = y.shape[1]\n",
    "nr_tokens = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:00:34.983006Z",
     "start_time": "2018-05-01T19:00:34.980991Z"
    }
   },
   "outputs": [],
   "source": [
    "# decoder_input_data = keras.utils.to_categorical(y, num_classes=nr_tokens)\n",
    "# decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:01:03.243621Z",
     "start_time": "2018-05-01T19:01:02.910441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_inputs (InputLayer)     (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             448         encoder_inputs[0][0]             \n",
      "                                                                 decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               [(None, 128), (None, 61824       shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               (None, 7, 128)       61824       shared_embedding[1][0]           \n",
      "                                                                 encoder_gru[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 7, 14)        1806        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 125,902\n",
      "Trainable params: 125,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shared_embedding = L.Embedding(nr_tokens, EMBEDDING_DIM, name='shared_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = shared_embedding(encoder_inputs)\n",
    "encoder_gru = L.GRU(LATENT_DIM, return_state=True, name='encoder_gru')\n",
    "_, encoder_states = encoder_gru(encoder_embeddings)\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target,), dtype='int32', name='decoder_inputs')\n",
    "decoder_embeddings = shared_embedding(decoder_inputs)\n",
    "decoder_gru = L.GRU(LATENT_DIM, return_sequences=True, name='decoder_gru')(decoder_embeddings, initial_state=encoder_states)\n",
    "decoder_outputs = L.Dense(nr_tokens, activation='softmax', name='decoder_outputs')(decoder_gru)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T19:01:05.895130Z",
     "start_time": "2018-05-01T19:01:05.857415Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=2.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-01T19:01:12.164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 6s 701us/step - loss: 0.7807 - val_loss: 0.0170\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 4s 457us/step - loss: 0.0073 - val_loss: 0.0033\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 4s 459us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.0011 - val_loss: 7.9654e-04\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 4s 468us/step - loss: 6.4027e-04 - val_loss: 5.0951e-04\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 4s 459us/step - loss: 4.2534e-04 - val_loss: 3.5179e-04\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 4s 463us/step - loss: 3.0121e-04 - val_loss: 2.5564e-04\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 4s 470us/step - loss: 2.2284e-04 - val_loss: 1.9260e-04\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 4s 460us/step - loss: 1.7017e-04 - val_loss: 1.4913e-04\n",
      "Epoch 10/10\n",
      "2208/8000 [=======>......................] - ETA: 2s - loss: 1.4480e-04"
     ]
    }
   ],
   "source": [
    "model.fit([X, y], y_one_hot, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-01T18:09:48.699675Z",
     "start_time": "2018-05-01T18:09:46.690Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(['^360+120$']), padding='post', maxlen=X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
