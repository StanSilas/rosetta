{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.623027Z",
     "start_time": "2018-05-05T12:26:40.736383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.626895Z",
     "start_time": "2018-05-05T12:26:41.624295Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.632299Z",
     "start_time": "2018-05-05T12:26:41.628476Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '$'\n",
    "\n",
    "SIZE = 100_000\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 16\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.639060Z",
     "start_time": "2018-05-05T12:26:41.633950Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_equations_df(size, min_value=0, max_value=9999, operations={'+': np.add, '-': np.subtract}):\n",
    "    df = pd.DataFrame()\n",
    "    df['a'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['b'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['op'] = np.random.choice(list(operations.keys()), size)\n",
    "    df['result'] = np.zeros(size, dtype='int')\n",
    "    for symbol, calc in operations.items():\n",
    "        df.loc[df.op == symbol, 'result'] = calc(df[df.op == symbol]['a'], df[df.op == symbol]['b'])\n",
    "        \n",
    "    df['input_texts'] = df.a.astype(str) + df.op + df.b.astype(str)\n",
    "    df['target_texts'] = START + df.result.astype(str) + END\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.890392Z",
     "start_time": "2018-05-05T12:26:41.640652Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_equations_df(SIZE) #, min_value=0, max_value=50, operations={'+': np.add})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:41.896773Z",
     "start_time": "2018-05-05T12:26:41.891799Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.concat([df.input_texts, df.target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:42.866587Z",
     "start_time": "2018-05-05T12:26:41.898221Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters=None, char_level=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:43.597933Z",
     "start_time": "2018-05-05T12:26:42.868018Z"
    }
   },
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(df.input_sequences, padding='post')\n",
    "y = keras.preprocessing.sequence.pad_sequences(df.target_sequences, padding='post')\n",
    "y_t_output = keras.utils.to_categorical(y[:,1:], num_classes=len(tokenizer.word_index)+1)\n",
    "x_t_input = y[:,:-1]\n",
    "\n",
    "max_len_input = X.shape[1]\n",
    "max_len_target = x_t_input.shape[1]\n",
    "nr_tokens = y_t_output.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:43.609092Z",
     "start_time": "2018-05-05T12:26:43.599251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '^': 10,\n",
       " '$': 11,\n",
       " '0': 12,\n",
       " '-': 13,\n",
       " '+': 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100000, 6, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "nr_tokens\n",
    "y_t_output.shape\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:44.760641Z",
     "start_time": "2018-05-05T12:26:43.610524Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_gru = L.GRU(LATENT_DIM, dropout=0.5, return_state=True, name='encoder_gru')\n",
    "decoder_gru = L.GRU(LATENT_DIM, dropout=0.5, return_sequences=True, return_state=True, name='decoder_gru')\n",
    "decoder_dense = L.Dense(nr_tokens, activation='softmax', name='decoder_outputs')\n",
    "\n",
    "shared_embedding = L.Embedding(nr_tokens, EMBEDDING_DIM, mask_zero=True, name='shared_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = shared_embedding(encoder_inputs)\n",
    "_, encoder_states = encoder_gru(encoder_embeddings)\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target, ), dtype='int32', name='decoder_inputs')\n",
    "decoder_mask = L.Masking(mask_value=0)(decoder_inputs)\n",
    "decoder_embeddings_inputs = shared_embedding(decoder_mask)\n",
    "decoder_embeddings_outputs, _ = decoder_gru(decoder_embeddings_inputs, initial_state=encoder_states) \n",
    "decoder_outputs = decoder_dense(decoder_embeddings_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "inference_encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "inference_decoder_state_inputs = L.Input(shape=(LATENT_DIM, ), dtype='float32', name='inference_decoder_state_inputs')\n",
    "inference_decoder_embeddings_outputs, inference_decoder_states = decoder_gru(\n",
    "    decoder_embeddings_inputs,\n",
    "    initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_outputs = decoder_dense(inference_decoder_embeddings_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_inputs, inference_decoder_state_inputs], \n",
    "    [inference_decoder_outputs, inference_decoder_states]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:44.765677Z",
     "start_time": "2018-05-05T12:26:44.761835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_inputs (InputLayer)     (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         encoder_inputs[0][0]             \n",
      "                                                                 masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               [(None, 512), (None, 812544      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 812544      shared_embedding[1][0]           \n",
      "                                                                 encoder_gru[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,633,023\n",
      "Trainable params: 1,633,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inference_decoder_state_inputs  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 812544      shared_embedding[1][0]           \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 820,479\n",
      "Trainable params: 820,479\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "inference_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T12:26:44.805849Z",
     "start_time": "2018-05-05T12:26:44.767662Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=1.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T13:02:51.104104Z",
     "start_time": "2018-05-05T12:26:44.807587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "90000/90000 [==============================] - 110s 1ms/step - loss: 1.6280 - val_loss: 1.3818\n",
      "Epoch 2/20\n",
      "90000/90000 [==============================] - 110s 1ms/step - loss: 1.3478 - val_loss: 1.2995\n",
      "Epoch 3/20\n",
      "90000/90000 [==============================] - 109s 1ms/step - loss: 1.2746 - val_loss: 1.2551\n",
      "Epoch 4/20\n",
      "90000/90000 [==============================] - 110s 1ms/step - loss: 1.2287 - val_loss: 1.1867\n",
      "Epoch 5/20\n",
      "90000/90000 [==============================] - 111s 1ms/step - loss: 1.1923 - val_loss: 1.1493\n",
      "Epoch 6/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.1594 - val_loss: 1.1454\n",
      "Epoch 7/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.1367 - val_loss: 1.1158\n",
      "Epoch 8/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.1158 - val_loss: 1.0910\n",
      "Epoch 9/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 1.0724 - val_loss: 1.0392\n",
      "Epoch 10/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 1.0075 - val_loss: 0.9993\n",
      "Epoch 11/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.9615 - val_loss: 0.9943\n",
      "Epoch 12/20\n",
      "90000/90000 [==============================] - 109s 1ms/step - loss: 0.9345 - val_loss: 0.9138\n",
      "Epoch 13/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.9213 - val_loss: 0.9386\n",
      "Epoch 14/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.9033 - val_loss: 0.9083\n",
      "Epoch 15/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.8854 - val_loss: 0.8723\n",
      "Epoch 16/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.8754 - val_loss: 0.9463\n",
      "Epoch 17/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.8674 - val_loss: 0.8579\n",
      "Epoch 18/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.8419 - val_loss: 0.7996\n",
      "Epoch 19/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.8027 - val_loss: 0.7862\n",
      "Epoch 20/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.7731 - val_loss: 0.7396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f234c7f3ba8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, x_t_input], y_t_output, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T13:02:51.109719Z",
     "start_time": "2018-05-05T13:02:51.105795Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, max_len_target))\n",
    "    target_seq[0, 0] = tokenizer.word_index[START]\n",
    "    \n",
    "    tokens = {idx: token for (token, idx) in tokenizer.word_index.items()}\n",
    "    \n",
    "    decoded_sequence = ''\n",
    "    for i in range(max_len_target):\n",
    "        output_tokens, output_states = inference_decoder_model.predict(\n",
    "            [target_seq, states_value]\n",
    "        )\n",
    "        \n",
    "        sampled_token_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_token = tokens.get(sampled_token_idx, '.')\n",
    "        if sampled_token == END:\n",
    "            break\n",
    "        decoded_sequence += sampled_token\n",
    "            \n",
    "        target_seq[0, 0] = sampled_token_idx\n",
    "        states_value = output_states\n",
    "    \n",
    "    return decoded_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T13:02:51.436296Z",
     "start_time": "2018-05-05T13:02:51.111849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=got: 94, exp: 2\n",
      "9+11=got: 998, exp: 20\n",
      "21+34=got: 191, exp: 55\n",
      "359+468=got: 836, exp: 827\n",
      "1359+468=got: 1837, exp: 1827\n",
      "1-1=got: -940, exp: 0\n",
      "19-1=got: -2984, exp: 18\n",
      "34-359=got: -394, exp: -325\n",
      "1359-468=got: 858, exp: 891\n"
     ]
    }
   ],
   "source": [
    "for calc in ['1+1', '9+11', '21+34', '359+468', '1359+468', '1-1', '19-1', '34-359', '1359-468']:\n",
    "    input_seq = keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenizer.texts_to_sequences([calc]), \n",
    "        padding='post', \n",
    "        maxlen=X.shape[1]\n",
    "    )\n",
    "    print(f\"{calc}=got: {decode_sequence(input_seq)}, exp: {eval(calc)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
