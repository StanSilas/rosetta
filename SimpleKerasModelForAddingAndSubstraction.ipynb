{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.104607Z",
     "start_time": "2018-05-07T10:38:32.101060Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.111597Z",
     "start_time": "2018-05-07T10:38:32.106288Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.117300Z",
     "start_time": "2018-05-07T10:38:32.113674Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '$'\n",
    "\n",
    "SIZE = 100_000\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 16\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.124118Z",
     "start_time": "2018-05-07T10:38:32.119046Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_equations_df(size, min_value=0, max_value=9999, operations={'+': np.add, '-': np.subtract}):\n",
    "    df = pd.DataFrame()\n",
    "    df['a'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['b'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['op'] = np.random.choice(list(operations.keys()), size)\n",
    "    df['result'] = np.zeros(size, dtype='int')\n",
    "    for symbol, calc in operations.items():\n",
    "        df.loc[df.op == symbol, 'result'] = calc(df[df.op == symbol]['a'], df[df.op == symbol]['b'])\n",
    "        \n",
    "    df['input_texts'] = df.a.astype(str) + df.op + df.b.astype(str)\n",
    "    df['target_texts'] = START + df.result.astype(str) + END\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.382143Z",
     "start_time": "2018-05-07T10:38:32.125859Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_equations_df(SIZE) #, min_value=0, max_value=50, operations={'+': np.add})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:32.392491Z",
     "start_time": "2018-05-07T10:38:32.383898Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.concat([df.input_texts, df.target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:33.407659Z",
     "start_time": "2018-05-07T10:38:32.394148Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters=None, char_level=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:34.134072Z",
     "start_time": "2018-05-07T10:38:33.409296Z"
    }
   },
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(df.input_sequences, padding='post')\n",
    "y = keras.preprocessing.sequence.pad_sequences(df.target_sequences, padding='post')\n",
    "y_t_output = keras.utils.to_categorical(y[:,1:], num_classes=len(tokenizer.word_index)+1)\n",
    "x_t_input = y[:,:-1]\n",
    "\n",
    "max_len_input = X.shape[1]\n",
    "max_len_target = x_t_input.shape[1]\n",
    "nr_tokens = y_t_output.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:34.142527Z",
     "start_time": "2018-05-07T10:38:34.135363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '^': 10,\n",
       " '$': 11,\n",
       " '0': 12,\n",
       " '-': 13,\n",
       " '+': 14}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100000, 6, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "nr_tokens\n",
    "y_t_output.shape\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:36.355529Z",
     "start_time": "2018-05-07T10:38:34.144317Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_gru_hidden = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, name='encoder_gru_hidden')\n",
    "encoder_gru = L.GRU(LATENT_DIM, dropout=DROPOUT, return_state=True, name='encoder_gru')\n",
    "decoder_gru_hidden = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, name='decoder_gru_hidden')\n",
    "decoder_gru = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, return_state=True, name='decoder_gru')\n",
    "# def encoder_gru(inputs):\n",
    "#     deep_layers = inputs\n",
    "#     for l in range(1, LAYERS):\n",
    "#         deep_layers = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, name=f'encoder_deep_layer_{l}')(deep_layers)\n",
    "#     return L.GRU(LATENT_DIM, dropout=DROPOUT, return_state=True, name='encoder_gru')(deep_layers)\n",
    "# \n",
    "# def decoder_gru(inputs, initial_state):\n",
    "#     deep_layers = inputs\n",
    "#     for l in range(1, LAYERS):\n",
    "#         deep_layers = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, name=f'decoder_deep_layer_{l}')(\n",
    "#             deep_layers, initial_state=initial_state\n",
    "#         )\n",
    "#     return L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, return_state=True, name='decoder_gru')(\n",
    "#         deep_layers, initial_state=initial_state\n",
    "#     )\n",
    "\n",
    "decoder_dense = L.Dense(nr_tokens, activation='softmax', name='decoder_outputs')\n",
    "\n",
    "shared_embedding = L.Embedding(nr_tokens, EMBEDDING_DIM, mask_zero=True, name='shared_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = shared_embedding(encoder_inputs)\n",
    "encoder_hidden_layers = encoder_gru_hidden(encoder_embeddings)\n",
    "_, encoder_states = encoder_gru(encoder_hidden_layers)\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target, ), dtype='int32', name='decoder_inputs')\n",
    "decoder_mask = L.Masking(mask_value=0)(decoder_inputs)\n",
    "decoder_embeddings_inputs = shared_embedding(decoder_mask)\n",
    "decoder_hidden_layers = decoder_gru_hidden(decoder_embeddings_inputs, initial_state=encoder_states)\n",
    "decoder_embeddings_outputs, _ = decoder_gru(decoder_hidden_layers, initial_state=encoder_states) \n",
    "decoder_outputs = decoder_dense(decoder_embeddings_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "inference_encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "inference_decoder_state_inputs = L.Input(shape=(LATENT_DIM, ), dtype='float32', name='inference_decoder_state_inputs')\n",
    "inference_decoder_hidden_layers = decoder_gru_hidden(\n",
    "    decoder_embeddings_inputs, initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_embeddings_outputs, inference_decoder_states = decoder_gru(\n",
    "    inference_decoder_hidden_layers, initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_outputs = decoder_dense(inference_decoder_embeddings_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_inputs, inference_decoder_state_inputs], \n",
    "    [inference_decoder_outputs, inference_decoder_states]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:36.360879Z",
     "start_time": "2018-05-07T10:38:36.356894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_4 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_inputs (InputLayer)     (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         encoder_inputs[0][0]             \n",
      "                                                                 masking_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru_hidden (GRU)        (None, 9, 512)       812544      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               [(None, 512), (None, 1574400     encoder_gru_hidden[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru_hidden (GRU)        (None, 6, 512)       812544      shared_embedding[1][0]           \n",
      "                                                                 encoder_gru[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 1574400     decoder_gru_hidden[0][0]         \n",
      "                                                                 encoder_gru[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 4,781,823\n",
      "Trainable params: 4,781,823\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_4 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         masking_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inference_decoder_state_inputs  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru_hidden (GRU)        (None, 6, 512)       812544      shared_embedding[1][0]           \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 1574400     decoder_gru_hidden[1][0]         \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,394,879\n",
      "Trainable params: 2,394,879\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "inference_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:38:36.394601Z",
     "start_time": "2018-05-07T10:38:36.362375Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=1.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:46:45.204250Z",
     "start_time": "2018-05-07T10:38:36.395977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "90000/90000 [==============================] - 27s 297us/step - loss: 1.5821 - val_loss: 1.4257\n",
      "Epoch 2/20\n",
      "90000/90000 [==============================] - 24s 270us/step - loss: 1.3077 - val_loss: 1.2116\n",
      "Epoch 3/20\n",
      "90000/90000 [==============================] - 23s 260us/step - loss: 1.2270 - val_loss: 1.1960\n",
      "Epoch 4/20\n",
      "90000/90000 [==============================] - 25s 273us/step - loss: 1.1437 - val_loss: 1.0228\n",
      "Epoch 5/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.9969 - val_loss: 0.9042\n",
      "Epoch 6/20\n",
      "90000/90000 [==============================] - 24s 264us/step - loss: 0.9121 - val_loss: 0.8743\n",
      "Epoch 7/20\n",
      "90000/90000 [==============================] - 24s 266us/step - loss: 0.8686 - val_loss: 0.8129\n",
      "Epoch 8/20\n",
      "90000/90000 [==============================] - 24s 266us/step - loss: 0.8376 - val_loss: 0.8062\n",
      "Epoch 9/20\n",
      "90000/90000 [==============================] - 24s 269us/step - loss: 0.8191 - val_loss: 0.7808\n",
      "Epoch 10/20\n",
      "90000/90000 [==============================] - 24s 269us/step - loss: 0.8012 - val_loss: 0.7960\n",
      "Epoch 11/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7872 - val_loss: 0.7772\n",
      "Epoch 12/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7740 - val_loss: 0.7541\n",
      "Epoch 13/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7666 - val_loss: 0.7400\n",
      "Epoch 14/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7579 - val_loss: 0.7419\n",
      "Epoch 15/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7496 - val_loss: 0.7173\n",
      "Epoch 16/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7441 - val_loss: 0.7362\n",
      "Epoch 17/20\n",
      "90000/90000 [==============================] - 25s 278us/step - loss: 0.7361 - val_loss: 0.7112\n",
      "Epoch 18/20\n",
      "90000/90000 [==============================] - 25s 274us/step - loss: 0.7300 - val_loss: 0.7248\n",
      "Epoch 19/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7214 - val_loss: 0.7079\n",
      "Epoch 20/20\n",
      "90000/90000 [==============================] - 24s 268us/step - loss: 0.7164 - val_loss: 0.6979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa17bc93ac8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, x_t_input], y_t_output, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:46:45.211434Z",
     "start_time": "2018-05-07T10:46:45.205911Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, max_len_target))\n",
    "    target_seq[0, 0] = tokenizer.word_index[START]\n",
    "    \n",
    "    tokens = {idx: token for (token, idx) in tokenizer.word_index.items()}\n",
    "    \n",
    "    decoded_sequence = ''\n",
    "    for i in range(max_len_target):\n",
    "        output_tokens, output_states = inference_decoder_model.predict(\n",
    "            [target_seq, states_value]\n",
    "        )\n",
    "        \n",
    "        sampled_token_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_token = tokens.get(sampled_token_idx, '.')\n",
    "        if sampled_token == END:\n",
    "            break\n",
    "        decoded_sequence += sampled_token\n",
    "            \n",
    "        target_seq[0, 0] = sampled_token_idx\n",
    "        states_value = output_states\n",
    "    \n",
    "    return decoded_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T10:46:46.334844Z",
     "start_time": "2018-05-07T10:46:45.213319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=got: -749, exp: 2\n",
      "9+11=got: 13289, exp: 20\n",
      "21+34=got: 149, exp: 55\n",
      "359+468=got: 839, exp: 827\n",
      "1359+468=got: 17854, exp: 1827\n",
      "1-1=got: -799, exp: 0\n",
      "19-1=got: -3061, exp: 18\n",
      "34-359=got: -479, exp: -325\n",
      "1359-468=got: 958, exp: 891\n"
     ]
    }
   ],
   "source": [
    "for calc in ['1+1', '9+11', '21+34', '359+468', '1359+468', '1-1', '19-1', '34-359', '1359-468']:\n",
    "    input_seq = keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenizer.texts_to_sequences([calc]), \n",
    "        padding='post', \n",
    "        maxlen=X.shape[1]\n",
    "    )\n",
    "    print(f\"{calc}=got: {decode_sequence(input_seq)}, exp: {eval(calc)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
