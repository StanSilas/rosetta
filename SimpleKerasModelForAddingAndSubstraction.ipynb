{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.546758Z",
     "start_time": "2018-05-05T11:05:42.695734Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.550702Z",
     "start_time": "2018-05-05T11:05:43.547983Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.556102Z",
     "start_time": "2018-05-05T11:05:43.552600Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '$'\n",
    "\n",
    "SIZE = 100_000\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 16\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.562203Z",
     "start_time": "2018-05-05T11:05:43.557462Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_equations_df(size, min_value=0, max_value=9999, operations={'+': np.add, '-': np.subtract}):\n",
    "    df = pd.DataFrame()\n",
    "    df['a'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['b'] = np.random.randint(low=min_value, high=max_value, size=size)\n",
    "    df['op'] = np.random.choice(list(operations.keys()), size)\n",
    "    df['result'] = np.zeros(size, dtype='int')\n",
    "    for symbol, calc in operations.items():\n",
    "        df.loc[df.op == symbol, 'result'] = calc(df[df.op == symbol]['a'], df[df.op == symbol]['b'])\n",
    "        \n",
    "    df['input_texts'] = df.a.astype(str) + df.op + df.b.astype(str)\n",
    "    df['target_texts'] = START + df.result.astype(str) + END\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.810571Z",
     "start_time": "2018-05-05T11:05:43.563625Z"
    }
   },
   "outputs": [],
   "source": [
    "df = create_equations_df(SIZE) #, min_value=0, max_value=50, operations={'+': np.add})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:43.818030Z",
     "start_time": "2018-05-05T11:05:43.812122Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.concat([df.input_texts, df.target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:44.792200Z",
     "start_time": "2018-05-05T11:05:43.819485Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters=None, char_level=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:45.573183Z",
     "start_time": "2018-05-05T11:05:44.793767Z"
    }
   },
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(df.input_sequences, padding='post')\n",
    "y = keras.preprocessing.sequence.pad_sequences(df.target_sequences, padding='post')\n",
    "y_t_output = keras.utils.to_categorical(y[:,1:], num_classes=len(tokenizer.word_index)+1)\n",
    "x_t_input = y[:,:-1]\n",
    "\n",
    "max_len_input = X.shape[1]\n",
    "max_len_target = x_t_input.shape[1]\n",
    "nr_tokens = y_t_output.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:45.584021Z",
     "start_time": "2018-05-05T11:05:45.574488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '^': 10,\n",
       " '$': 11,\n",
       " '0': 12,\n",
       " '-': 13,\n",
       " '+': 14}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(100000, 6, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index\n",
    "nr_tokens\n",
    "y_t_output.shape\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:46.755598Z",
     "start_time": "2018-05-05T11:05:45.585356Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_gru = L.GRU(LATENT_DIM, return_state=True, name='encoder_gru')\n",
    "decoder_gru = L.GRU(LATENT_DIM, return_sequences=True, return_state=True, name='decoder_gru')\n",
    "decoder_dense = L.Dense(nr_tokens, activation='softmax', name='decoder_outputs')\n",
    "\n",
    "shared_embedding = L.Embedding(nr_tokens, EMBEDDING_DIM, mask_zero=True, name='shared_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = shared_embedding(encoder_inputs)\n",
    "_, encoder_states = encoder_gru(encoder_embeddings)\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target, ), dtype='int32', name='decoder_inputs')\n",
    "decoder_mask = L.Masking(mask_value=0)(decoder_inputs)\n",
    "decoder_embeddings_inputs = shared_embedding(decoder_mask)\n",
    "decoder_embeddings_outputs, _ = decoder_gru(decoder_embeddings_inputs, initial_state=encoder_states) \n",
    "decoder_outputs = decoder_dense(decoder_embeddings_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "inference_encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "inference_decoder_state_inputs = L.Input(shape=(LATENT_DIM, ), dtype='float32', name='inference_decoder_state_inputs')\n",
    "inference_decoder_embeddings_outputs, inference_decoder_states = decoder_gru(\n",
    "    decoder_embeddings_inputs,\n",
    "    initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_outputs = decoder_dense(inference_decoder_embeddings_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_inputs, inference_decoder_state_inputs], \n",
    "    [inference_decoder_outputs, inference_decoder_states]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:46.761988Z",
     "start_time": "2018-05-05T11:05:46.757494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_inputs (InputLayer)     (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         encoder_inputs[0][0]             \n",
      "                                                                 masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gru (GRU)               [(None, 512), (None, 812544      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 812544      shared_embedding[1][0]           \n",
      "                                                                 encoder_gru[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,633,023\n",
      "Trainable params: 1,633,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 6)            0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             240         masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inference_decoder_state_inputs  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 6, 512), (No 812544      shared_embedding[1][0]           \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 6, 15)        7695        decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 820,479\n",
      "Trainable params: 820,479\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "inference_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:05:46.804926Z",
     "start_time": "2018-05-05T11:05:46.763612Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=1.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:41:52.326762Z",
     "start_time": "2018-05-05T11:05:46.806437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 1.6467 - val_loss: 1.5114\n",
      "Epoch 2/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.3663 - val_loss: 1.2778\n",
      "Epoch 3/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.2369 - val_loss: 1.2174\n",
      "Epoch 4/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.1637 - val_loss: 1.1554\n",
      "Epoch 5/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 1.1049 - val_loss: 1.0689\n",
      "Epoch 6/20\n",
      "90000/90000 [==============================] - 112s 1ms/step - loss: 1.0709 - val_loss: 1.0429\n",
      "Epoch 7/20\n",
      "90000/90000 [==============================] - 111s 1ms/step - loss: 1.0435 - val_loss: 1.0458\n",
      "Epoch 8/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.0289 - val_loss: 1.1021\n",
      "Epoch 9/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 1.0114 - val_loss: 1.0105\n",
      "Epoch 10/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9960 - val_loss: 1.0075\n",
      "Epoch 11/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9821 - val_loss: 0.9872\n",
      "Epoch 12/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9701 - val_loss: 0.9753\n",
      "Epoch 13/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.9648 - val_loss: 0.9466\n",
      "Epoch 14/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9475 - val_loss: 0.9804\n",
      "Epoch 15/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9446 - val_loss: 0.9448\n",
      "Epoch 16/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9318 - val_loss: 0.9565\n",
      "Epoch 17/20\n",
      "90000/90000 [==============================] - 107s 1ms/step - loss: 0.9134 - val_loss: 1.1254\n",
      "Epoch 18/20\n",
      "90000/90000 [==============================] - 108s 1ms/step - loss: 0.9133 - val_loss: 0.9029\n",
      "Epoch 19/20\n",
      "90000/90000 [==============================] - 112s 1ms/step - loss: 0.9002 - val_loss: 0.9608\n",
      "Epoch 20/20\n",
      "90000/90000 [==============================] - 112s 1ms/step - loss: 0.8926 - val_loss: 1.0480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62fdaf9748>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X, x_t_input], y_t_output, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:41:52.333153Z",
     "start_time": "2018-05-05T11:41:52.328673Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, max_len_target))\n",
    "    target_seq[0, 0] = tokenizer.word_index[START]\n",
    "    \n",
    "    tokens = {idx: token for (token, idx) in tokenizer.word_index.items()}\n",
    "    \n",
    "    decoded_sequence = ''\n",
    "    for i in range(max_len_target):\n",
    "        output_tokens, output_states = inference_decoder_model.predict(\n",
    "            [target_seq, states_value]\n",
    "        )\n",
    "        \n",
    "        sampled_token_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_token = tokens.get(sampled_token_idx, '.')\n",
    "        if sampled_token == END:\n",
    "            break\n",
    "        decoded_sequence += sampled_token\n",
    "            \n",
    "        target_seq[0, 0] = sampled_token_idx\n",
    "        states_value = output_states\n",
    "    \n",
    "    return decoded_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-05T11:41:52.590422Z",
     "start_time": "2018-05-05T11:41:52.334730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=got: 179, exp: 2\n",
      "9+11=got: -7089, exp: 20\n",
      "21+34=got: 190, exp: 55\n",
      "359+468=got: 836, exp: 827\n",
      "1359+468=got: 1800, exp: 1827\n",
      "1-1=got: 1985, exp: 0\n",
      "19-1=got: 178, exp: 18\n",
      "34-359=got: -305, exp: -325\n",
      "1359-468=got: 799, exp: 891\n"
     ]
    }
   ],
   "source": [
    "for calc in ['1+1', '9+11', '21+34', '359+468', '1359+468', '1-1', '19-1', '34-359', '1359-468']:\n",
    "    input_seq = keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenizer.texts_to_sequences([calc]), \n",
    "        padding='post', \n",
    "        maxlen=X.shape[1]\n",
    "    )\n",
    "    print(f\"{calc}=got: {decode_sequence(input_seq)}, exp: {eval(calc)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
