{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on large dataset with already implemented BeamSearch but without attention model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After [implementing Beamsearch](BeamSearchForMachineTranslation.ipynb), I'll now train it on a large dataset. The goal is beside a better translation quality also to show problems arising without attention model (that is needed for larger texts). \n",
    "As trainings set I use the [European Parliament Proceedings Parallel Corpus 1996-2011](http://statmt.org/europarl/) German-English corpus with medium sized sentences.\n",
    "\n",
    "Again, I'll refactor the code a bit, putting most of the implementation details into modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:22.894976Z",
     "start_time": "2018-05-24T17:04:20.882586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    " \n",
    "import bytepairencoding as bpe\n",
    "import seq2seq\n",
    "from utils.download import download_and_extract_resources\n",
    "from utils.linguistic import bleu_scores_europarl, read_europarl, preprocess_input_europarl as preprocess\n",
    "\n",
    "\n",
    "# Fixing random state ensure reproducible results\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)\n",
    "\n",
    "pd.set_option('max_colwidth', 60)  # easier to read texts in e.g. df.head()\n",
    "\n",
    "# technical detail so that an instance (maybe running in a different window)\n",
    "# doesn't take all the GPU memory resulting in some strange error messages\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:22.898831Z",
     "start_time": "2018-05-24T17:04:22.896142Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_INPUT_LENGTH = 100  # was 50\n",
    "MAX_TARGET_LENGTH = 125  # was 65\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 300\n",
    "BPE_MERGE_OPERATIONS = 5_000  # I'd love to use 10_000 x 300, but this one is broken: https://github.com/bheinzerling/bpemb/issues/6\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32  # was 64, but need to reduced so a batch still fits in GPU memory\n",
    "DROPOUT = 0.5\n",
    "TEST_SIZE = 2_500  # was 500\n",
    "EMBEDDING_TRAINABLE = True  # Improves results significant and for at least it's not the most dominant training time factor (that's the output softmax layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T13:03:31.674082Z",
     "start_time": "2018-05-08T13:03:31.670919Z"
    }
   },
   "source": [
    "## Download and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:22.906475Z",
     "start_time": "2018-05-24T17:04:22.900157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-en.tgz already downloaded (188.6 MB)\n",
      "en.wiki.bpe.op5000.model already downloaded (0.3 MB)\n",
      "en.wiki.bpe.op5000.d300.w2v.bin.tar.gz already downloaded (6.2 MB)\n",
      "de.wiki.bpe.op5000.model already downloaded (0.3 MB)\n",
      "de.wiki.bpe.op5000.d300.w2v.bin.tar.gz already downloaded (5.7 MB)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data'\n",
    "INPUT_LANG = 'en'\n",
    "TARGET_LANG = 'de'\n",
    "LANGUAGES = [INPUT_LANG, TARGET_LANG]\n",
    "BPE_URL = {lang: f'http://cosyne.h-its.org/bpemb/data/{lang}/' for lang in LANGUAGES}\n",
    "BPE_MODEL_NAME = {lang: f'{lang}.wiki.bpe.op{BPE_MERGE_OPERATIONS}.model' for lang in LANGUAGES}\n",
    "BPE_WORD2VEC_NAME = {lang: f'{lang}.wiki.bpe.op{BPE_MERGE_OPERATIONS}.d{EMBEDDING_DIM}.w2v.bin' for lang in LANGUAGES}\n",
    "\n",
    "EXTERNAL_RESOURCES = {\n",
    "    # Europarl Corpus\n",
    "    'de-en.tgz': 'http://statmt.org/europarl/v7/de-en.tgz',\n",
    "    \n",
    "    # Bytepairencoding subwords (_MODEL_) and pretrained embeddings (_WORD2VEC_)\n",
    "    BPE_MODEL_NAME[INPUT_LANG]: f'{BPE_URL[INPUT_LANG]}/{BPE_MODEL_NAME[INPUT_LANG]}',\n",
    "    BPE_WORD2VEC_NAME[INPUT_LANG] + '.tar.gz': f'{BPE_URL[INPUT_LANG]}/{BPE_WORD2VEC_NAME[INPUT_LANG]}' + '.tar.gz',\n",
    "    BPE_MODEL_NAME[TARGET_LANG]: f'{BPE_URL[TARGET_LANG]}/{BPE_MODEL_NAME[TARGET_LANG]}',\n",
    "    BPE_WORD2VEC_NAME[TARGET_LANG] + '.tar.gz': f'{BPE_URL[TARGET_LANG]}/{BPE_WORD2VEC_NAME[TARGET_LANG]}' + '.tar.gz',\n",
    "}\n",
    "\n",
    "download_and_extract_resources(fnames_and_urls=EXTERNAL_RESOURCES, dest_path=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:24.870498Z",
     "start_time": "2018-05-24T17:04:22.907962Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'input_texts': read_europarl(INPUT_LANG),\n",
    "    'target_texts': read_europarl(TARGET_LANG)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:25.800656Z",
     "start_time": "2018-05-24T17:04:24.872993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr total input: 1920209\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>input_length</th>\n",
       "      <th>target_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resumption of the session</td>\n",
       "      <td>wiederaufnahme der sitzungsperiode</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i declare resumed the session of the european parliament...</td>\n",
       "      <td>ich erkläre die am freitag, dem 0. dezember unterbrochen...</td>\n",
       "      <td>203</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>although, as you will have seen, the dreaded 'millennium...</td>\n",
       "      <td>wie sie feststellen konnten, ist der gefürchtete \"millen...</td>\n",
       "      <td>191</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you have requested a debate on this subject in the cours...</td>\n",
       "      <td>im parlament besteht der wunsch nach einer aussprache im...</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the meantime, i should like to observe a minute' s si...</td>\n",
       "      <td>heute möchte ich sie bitten - das ist auch der wunsch ei...</td>\n",
       "      <td>232</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input_texts  \\\n",
       "0                                    resumption of the session   \n",
       "1  i declare resumed the session of the european parliament...   \n",
       "2  although, as you will have seen, the dreaded 'millennium...   \n",
       "3  you have requested a debate on this subject in the cours...   \n",
       "4  in the meantime, i should like to observe a minute' s si...   \n",
       "\n",
       "                                                  target_texts  input_length  \\\n",
       "0                           wiederaufnahme der sitzungsperiode            25   \n",
       "1  ich erkläre die am freitag, dem 0. dezember unterbrochen...           203   \n",
       "2  wie sie feststellen konnten, ist der gefürchtete \"millen...           191   \n",
       "3  im parlament besteht der wunsch nach einer aussprache im...           105   \n",
       "4  heute möchte ich sie bitten - das ist auch der wunsch ei...           232   \n",
       "\n",
       "   target_length  \n",
       "0             34  \n",
       "1            217  \n",
       "2            185  \n",
       "3            110  \n",
       "4            217  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nr total input:\", len(df))\n",
    "df['input_length'] = df.input_texts.apply(len)\n",
    "df['target_length'] = df.target_texts.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter translations (only sentences shorter than a given length)\n",
    "\n",
    "With a full working machine translation system, it's of course better to train on all data (plus maybe some augmented data). Without attention (and maybe copy mechanism, dynamic memory, ...) there's no point anyway in it, but it also reduces training time (a full training on ~2 Mio translations might take days, even with a good GPU).\n",
    "I use different length for input (english) than target (german) language as german is more verbose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:25.973740Z",
     "start_time": "2018-05-24T17:04:25.802264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with length between (1, input=100/target=125) characters: 597331\n"
     ]
    }
   ],
   "source": [
    "non_empty = (df.input_length > 1) & (df.target_length > 1)  # there are empty phrases like '\\n' --> 'Frau Präsidentin\\n'\n",
    "short_inputs = (df.input_length < MAX_INPUT_LENGTH) & (df.target_length < MAX_TARGET_LENGTH)\n",
    "print(f'Sentences with length between (1, input={MAX_INPUT_LENGTH}/target={MAX_TARGET_LENGTH}) characters:', sum(non_empty & short_inputs))\n",
    "df = df[non_empty & short_inputs]\n",
    "gc.collect();  # df with filtered sentences is significant smaller, so time to garbage collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (pretrained) Bytepairs\n",
    "\n",
    "I need the subwords dictionary (in `BPE_WORD2VEC_NAME`), the pretrained embeddings (in `BPE_MODEL_NAME`) and a [sentencepiece](https://github.com/google/sentencepiece) handler that can encode/decode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:04:26.092866Z",
     "start_time": "2018-05-24T17:04:25.975329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English subwords ['▁this', '▁is', '▁a', '▁test', '▁for', '▁pre', 'tr', 'ained', '▁by', 'te', 'pa', 'ire', 'm', 'bed', 'd', 'ings']\n",
      "German subwords ['▁d', 'as', '▁is', 't', '▁e', 'in', '▁test', '▁f', 'ür', '▁v', 'ort', 'rain', 'ier', 'te', '▁ze', 'ic', 'hen', 'gr', 'up', 'p', 'en']\n"
     ]
    }
   ],
   "source": [
    "bpe_input, bpe_target = [bpe.Bytepairencoding(\n",
    "    word2vec_fname=os.path.join(PATH, BPE_WORD2VEC_NAME[lang]),\n",
    "    sentencepiece_fname=os.path.join(PATH, BPE_MODEL_NAME[lang]),\n",
    ") for lang in [INPUT_LANG, TARGET_LANG]] \n",
    "print(\"English subwords\", bpe_input.sentencepiece.EncodeAsPieces(\"this is a test for pretrained bytepairembeddings\"))\n",
    "print(\"German subwords\", bpe_input.sentencepiece.EncodeAsPieces(\"das ist ein test für vortrainierte zeichengruppen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:05:11.740565Z",
     "start_time": "2018-05-24T17:04:26.094040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_sequences</th>\n",
       "      <th>target_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]</td>\n",
       "      <td>[1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 3005, 416, 77, 359, 4, 241, 4, 17, 76, 451, 782, 21,...</td>\n",
       "      <td>[1, 241, 156, 72, 3112, 54, 4, 39, 26, 95, 4739, 89, 937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 29, 140, 414, 3231, 8, 3106, 2484, 9, 451, 782, 21, ...</td>\n",
       "      <td>[1, 35, 2444, 2269, 2109, 625, 39, 26, 95, 4739, 89, 937...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1599, 134, 546, 4, 19, 9, 918, 6, 535, 5, 2]</td>\n",
       "      <td>[1, 1161, 2266, 52, 4, 132, 2232, 1516, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 530, 3, 414, 1434, 35, 4, 305, 186, 321, 366, 18, 19...</td>\n",
       "      <td>[1, 835, 19, 684, 494, 21, 161, 48, 838, 30, 4, 781, 67,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input_sequences  \\\n",
       "0                     [1, 344, 146, 498, 90, 6, 3, 3235, 90, 2]   \n",
       "5   [1, 3005, 416, 77, 359, 4, 241, 4, 17, 76, 451, 782, 21,...   \n",
       "6   [1, 29, 140, 414, 3231, 8, 3106, 2484, 9, 451, 782, 21, ...   \n",
       "7              [1, 1599, 134, 546, 4, 19, 9, 918, 6, 535, 5, 2]   \n",
       "12  [1, 530, 3, 414, 1434, 35, 4, 305, 186, 321, 366, 18, 19...   \n",
       "\n",
       "                                               target_sequences  \n",
       "0                 [1, 247, 351, 750, 5, 934, 43, 3158, 4762, 2]  \n",
       "5   [1, 241, 156, 72, 3112, 54, 4, 39, 26, 95, 4739, 89, 937...  \n",
       "6   [1, 35, 2444, 2269, 2109, 625, 39, 26, 95, 4739, 89, 937...  \n",
       "7                 [1, 1161, 2266, 52, 4, 132, 2232, 1516, 3, 2]  \n",
       "12  [1, 835, 19, 684, 494, 21, 161, 48, 838, 30, 4, 781, 67,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now encode the texts into sequences of indexes of bytepairs\n",
    "df['input_sequences'] = df.input_texts.apply(bpe_input.subword_indices)\n",
    "df['target_sequences'] = df.target_texts.apply(bpe_target.subword_indices)\n",
    "df[['input_sequences', 'target_sequences']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:05:11.966448Z",
     "start_time": "2018-05-24T17:05:11.742153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 71)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those will be the inputs for the seq2seq model (that needs to know how long the sequences can get)\n",
    "max_len_input = df.input_sequences.apply(len).max()\n",
    "max_len_target = df.target_sequences.apply(len).max()\n",
    "(max_len_input, max_len_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T17:05:11.991504Z",
     "start_time": "2018-05-24T17:05:11.967820Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(np.arange(df.shape[0]), test_size=0.1, random_state=RANDOM_STATE)  # fixed random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:44:14.023430Z",
     "start_time": "2018-05-24T17:05:11.993260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16800/16800 [==============================] - 3163s 188ms/step - loss: 2.6356 - val_loss: 2.1203\n",
      "Epoch 2/20\n",
      "16800/16800 [==============================] - 3161s 188ms/step - loss: 2.1554 - val_loss: 1.9783\n",
      "Epoch 3/20\n",
      "16800/16800 [==============================] - 3166s 188ms/step - loss: 2.0454 - val_loss: 1.9150\n",
      "Epoch 4/20\n",
      "16800/16800 [==============================] - 3178s 189ms/step - loss: 1.9858 - val_loss: 1.8763\n",
      "Epoch 5/20\n",
      "16800/16800 [==============================] - 3173s 189ms/step - loss: 1.9459 - val_loss: 1.8492\n",
      "Epoch 6/20\n",
      "16800/16800 [==============================] - 3172s 189ms/step - loss: 1.9162 - val_loss: 1.8279\n",
      "Epoch 7/20\n",
      "16800/16800 [==============================] - 3168s 189ms/step - loss: 1.8937 - val_loss: 1.8150\n",
      "Epoch 8/20\n",
      "16800/16800 [==============================] - 3170s 189ms/step - loss: 1.8758 - val_loss: 1.8017\n",
      "Epoch 9/20\n",
      "16800/16800 [==============================] - 3170s 189ms/step - loss: 1.8610 - val_loss: 1.7940\n",
      "Epoch 10/20\n",
      "16800/16800 [==============================] - 3163s 188ms/step - loss: 1.8482 - val_loss: 1.7843\n",
      "Epoch 11/20\n",
      "16800/16800 [==============================] - 3163s 188ms/step - loss: 1.8372 - val_loss: 1.7767\n",
      "Epoch 12/20\n",
      "16800/16800 [==============================] - 3165s 188ms/step - loss: 1.8275 - val_loss: 1.7739\n",
      "Epoch 13/20\n",
      "16800/16800 [==============================] - 3165s 188ms/step - loss: 1.8197 - val_loss: 1.7617\n",
      "Epoch 14/20\n",
      "16800/16800 [==============================] - 3167s 188ms/step - loss: 1.8118 - val_loss: 1.7617\n",
      "Epoch 15/20\n",
      "16800/16800 [==============================] - 3166s 188ms/step - loss: 1.8052 - val_loss: 1.7542\n",
      "Epoch 16/20\n",
      "16800/16800 [==============================] - 3167s 189ms/step - loss: 1.7996 - val_loss: 1.7548\n",
      "Epoch 17/20\n",
      "16800/16800 [==============================] - 3205s 191ms/step - loss: 1.7943 - val_loss: 1.7501\n",
      "Epoch 18/20\n",
      "16800/16800 [==============================] - 3203s 191ms/step - loss: 1.7895 - val_loss: 1.7472\n",
      "Epoch 19/20\n",
      "16800/16800 [==============================] - 3236s 193ms/step - loss: 1.7852 - val_loss: 1.7431\n",
      "Epoch 20/20\n",
      "16800/16800 [==============================] - 3217s 191ms/step - loss: 1.7817 - val_loss: 1.7442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f31d6788978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s = seq2seq.Seq2SeqWithBPE(\n",
    "    bpe_input=bpe_input,\n",
    "    bpe_target=bpe_target,\n",
    "    max_len_input=max_len_input,\n",
    "    max_len_target=max_len_target\n",
    ")\n",
    "s2s.model.compile(optimizer=keras.optimizers.Adam(clipnorm=1., clipvalue=.5), loss='categorical_crossentropy')\n",
    "train_generator = s2s.create_batch_generator(train_ids, df.input_sequences, df.target_sequences, BATCH_SIZE)\n",
    "val_generator = s2s.create_batch_generator(val_ids, df.input_sequences, df.target_sequences, BATCH_SIZE)\n",
    "\n",
    "s2s.model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(len(train_ids) / BATCH_SIZE),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=np.ceil(len(val_ids) / BATCH_SIZE),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:44:14.260939Z",
     "start_time": "2018-05-25T10:44:14.024892Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'beamsearchlarge'\n",
    "s2s.model.save_weights(f'data/{name}_model_weights.h5')\n",
    "s2s.inference_encoder_model.save_weights(f'data/{name}_inference_encoder_model_weights.h5')\n",
    "s2s.inference_decoder_model.save_weights(f'data/{name}_inference_decoder_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:44:14.264676Z",
     "start_time": "2018-05-25T10:44:14.262319Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sentence, beam_width=5):\n",
    "    return s2s.decode_beam_search(pad_sequences(\n",
    "        [bpe_input.subword_indices(preprocess(sentence))],\n",
    "        padding='post',\n",
    "        maxlen=max_len_input,\n",
    "    ), beam_width=beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:44:22.167214Z",
     "start_time": "2018-05-25T10:44:14.266187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello.' --> 'helfen sie.'\n",
      "'you are welcome.' --> 'wir begrüßen sie.'\n",
      "'how do you do?' --> 'wie tun sie?'\n",
      "'i hate mondays.' --> 'ich meine das.'\n",
      "'i am a programmer.' --> 'ich bin ein programm.'\n",
      "'data is the new oil.' --> 'daten sind das neue öl.'\n",
      "'it could be worse.' --> 'es könnte schlimmer sein.'\n",
      "'i am on top of it.' --> 'ich bin dagegen.'\n",
      "'n° uno' --> 'änderungsantrag'\n",
      "'awesome!' --> 'nein!'\n",
      "'put your feet up!' --> 'nehmen sie das!'\n",
      "'from the start till the end!' --> 'aus dem ende!'\n",
      "'from dusk till dawn.' --> 'von der drehteu.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on some examples:\n",
    "EXAMPLES = [\n",
    "    'Hello.',\n",
    "    'You are welcome.',\n",
    "    'How do you do?',\n",
    "    'I hate mondays.',\n",
    "    'I am a programmer.',\n",
    "    'Data is the new oil.',\n",
    "    'It could be worse.',\n",
    "    \"I am on top of it.\",\n",
    "    \"N° Uno\",\n",
    "    \"Awesome!\",\n",
    "    \"Put your feet up!\",\n",
    "    \"From the start till the end!\",\n",
    "    \"From dusk till dawn.\",\n",
    "]\n",
    "for en in [sentence + '\\n' for sentence in EXAMPLES]:\n",
    "    print(f\"{preprocess(en)!r} --> {predict(en)!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:44:50.165732Z",
     "start_time": "2018-05-25T10:44:22.168562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original \"please rise, then, for this minute' s silence.\", got 'bitte gestatten sie mir also eine schweigeminute.', exp: 'ich bitte sie, sich zu einer schweigeminute zu erheben.'\n",
      "Original \"(the house rose and observed a minute' s silence)\", got '(das parlament erhebt sich zu einer schweigeminute.)', exp: '(das parlament erhebt sich zu einer schweigeminute.)'\n",
      "Original 'madam president, on a point of order.', got 'frau präsidentin, zur geschäftsordnung.', exp: 'frau präsidentin, zur geschäftsordnung.'\n",
      "Original 'if the house agrees, i shall do as mr evans has suggested.', got 'wenn der abgeordnete soviel ich einverstanden habe, dann habe ich das haus.', exp: 'wenn das haus damit einverstanden ist, werde ich dem vorschlag von herrn evans folgen.'\n",
      "Original 'madam president, on a point of order.', got 'frau präsidentin, zur geschäftsordnung.', exp: 'frau präsidentin, zur geschäftsordnung.'\n",
      "Original 'i would like your advice about rule 0 concerning inadmissibility.', got 'ich würde gerne ihre regelung auf artikel 0 der geschäftsordnung untergraben.', exp: 'könnten sie mir eine auskunft zu artikel 0 im zusammenhang mit der unzulässigkeit geben?'\n",
      "Original 'it says that this should be done despite the principle of relative stability.', got 'es wird gesagt, dass dies der grundsatz der stabilität ist.', exp: 'und zwar sollen derartige strafen trotz des grundsatzes der relativen stabilität verhängt werden.'\n",
      "Original 'this is all in accordance with the principles that we have always upheld.', got 'das ist alles, was wir mit den prinzipien gesagt haben.', exp: 'all dies entspricht den grundsätzen, die wir stets verteidigt haben.'\n",
      "Original 'thank you, mr segni, i shall do so gladly.', got 'ich danke ihnen, herr meció, herzlichen dank.', exp: 'vielen dank, herr segni, das will ich gerne tun.'\n",
      "Original 'indeed, it is quite in keeping with the positions this house has always adopted.', got 'in der tat hat die position der parlamente dieses parlaments stets angenommen.', exp: 'das ist ganz im sinne der position, die wir als parlament immer vertreten haben.'\n",
      "Original 'it is the case of alexander nikitin.', got 'das ist alexander nikitin.', exp: 'das ist der fall von alexander nikitin.'\n",
      "Original 'now, however, he is to go before the courts once more because the public prosecutor is appealing.', got 'jetzt müssen aber meine kolleginnen und kollegen weitermachen, daß die öffentlichkeit vorausgesetzt werden sollte.', exp: 'nun ist es aber so, daß er wieder angeklagt werden soll, weil der staatsanwalt in berufung geht.'\n",
      "Original 'but, madam president, my personal request has not been met.', got 'persönlich ist meiner meinung nach nicht der fall.', exp: 'dennoch, frau präsidentin, wurde meinem wunsch nicht entsprochen.'\n",
      "Original 'i would therefore once more ask you to ensure that we get a dutch channel as well.', got 'daher möchte ich sie bitten, uns noch einmal zu ändern.', exp: 'deshalb möchte ich sie nochmals ersuchen, dafür sorge zu tragen, daß auch ein niederländischer sender eingespeist wird.'\n",
      "Original 'it will, i hope, be examined in a positive light.', got 'ich hoffe, dass dies in einem positiven licht wird.', exp: 'ich hoffe, daß dort in ihrem sinne entschieden wird.'\n",
      "Original 'why has no air quality test been done on this particular building since we were elected?', got 'warum haben wir keinerlei plätze für diesen teststandards gewährleistet?', exp: 'weshalb wurde die luftqualität in diesem gebäude seit unserer wahl nicht ein einziges mal überprüft?'\n",
      "Original 'why has there been no health and safety committee meeting since 0?', got 'warum gibt es keine gesundheits- und sicherheitsrate von 0 bis 0?', exp: 'weshalb ist der arbeitsschutzausschuß seit 0 nicht ein einziges mal zusammengetreten?'\n",
      "Original 'why are there no fire instructions?', got 'warum gibt es keine feuerwaffen?', exp: 'warum finden keine brandschutzbelehrungen statt?'\n",
      "Original 'why have the staircases not been improved since my accident?', got 'warum ist die stabilisierungsbehörde nicht besser?', exp: 'warum wurde nach meinem unfall nichts unternommen, um die treppen sicherer zu machen?'\n"
     ]
    }
   ],
   "source": [
    "# Performance on training set:\n",
    "for en, de in df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T10:45:21.850498Z",
     "start_time": "2018-05-25T10:44:50.167097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'we congratulate you on a job very well done.', got 'wir gratulieren ihnen zu ihrer sehr guten arbeit.', exp: 'wir gratulieren dir zu deiner hervorragenden arbeit.'\n",
      "Original 'in this case, i strongly disagree with what was said by the previous speaker, carl schlyter.', got 'in diesem punkt stimme ich dem vorschlag von herrn schnellhardt nicht zu.', exp: 'in diesem fall widerspreche ich klar dem, was der vorredner, carl schlyter, gesagt hat.'\n",
      "Original 'it only makes sense to rebuild these if the refugees who fled are coming back.', got 'es ist nur so, wenn die flüchtlinge zurückgekehrt werden müssen.', exp: 'deren wiederaufbau ist nur dann von nutzen, wenn die flüchtlinge aus den betreffenden gebieten wieder zurückkehren.'\n",
      "Original 'eba: everything but arms.', got 'eurobonds: alles.', exp: 'eba: everything but arms.'\n",
      "Original 'in wider terms, this directive is not ambitious enough.', got 'diese richtlinie reicht nicht aus.', exp: 'generell gesehen fehlt es dieser richtlinie an ambitioniertheit.'\n",
      "Original 'it is an irresponsible mistake to spend public money to maintain this fleet.', got 'es ist ein fehler, den öffentlichen fehler zu machen.', exp: 'öffentliche gelder zur erhaltung dieser flotte zu verwenden ist ein verantwortungsloser fehler.'\n",
      "Original 'where better to ensure access to culture than through our libraries?', got 'was soll besser als zugang zu den bibliotheken?', exp: 'wo ließe sich der zugang zu kultur besser sichern als durch unsere bibliotheken?'\n",
      "Original 'i would like to advise you against this.', got 'ich möchte sie darum bitten.', exp: 'hiervor möchte ich warnen.'\n",
      "Original 'in writing. - (pt) it is essential to harmonise national safety procedures in member states.', got 'schriftlich. - (pt) es ist unbedingt notwendig, die nationalen harmonisierungsmaßnahmen in den bereichen zu harmonisieren.', exp: 'schriftlich. - (pt) es kommt jetzt darauf an, die nationalen sicherheitsverfahren in den mitgliedstaaten zu harmonisieren.'\n",
      "Original 'we know that shipbuilding is the last industrial sector to be subsidised.', got 'wir wissen, dass der sektor der schiffbauindustrie für den schiffbau schafft.', exp: 'wir wissen, dass der schiffbau der letzte subventionierte industriesektor ist.'\n",
      "Original 'we spent 0 million euros on this project in 0, and 0 million euros in 0.', got 'wir haben 0 0 euro pro jahr geleistet.', exp: 'im jahr 0 haben wir 0 millionen euro für dieses projekt ausgegeben, 0 dann 0 millionen euro.'\n",
      "Original 'the eventual solution to the chinese challenge is to be found not in china, but in africa itself.', got 'die lösung für die chinesen in china ist nicht in der toleranz.', exp: 'letztendlich liegt die antwort auf die chinesische herausforderung nicht in china, sondern in afrika selbst.'\n",
      "Original \"we in parliament will say 'yes' to new taxes but 'no' to more taxes.\", got 'wir werden sagen, das parlament \"nein\" lautet: \"ja, steuern\".', exp: 'wir im parlament werden neuen steuern zustimmen, zusätzlichen steuern jedoch eine klare absage erteilen.'\n",
      "Original 'however, in my view we must not rest on our laurels.', got 'aber ich glaube nicht, dass wir unsere auffassungen aufnehmen.', exp: 'meiner ansicht nach dürfen wir uns jedoch nicht auf unseren lorbeeren ausruhen.'\n",
      "Original 'i shall confine my comments to a few basic issues.', got 'ich werde mich auf einige prinzipien einigen.', exp: 'im folgenden werde ich mich auf einige grundlegende themen konzentrieren.'\n",
      "Original 'the greatest anxiety is being aroused by the damage to the fukushima nuclear power station.', got 'die große fukushimaanlage wird zerstört, daß das virus quaine zerstört wird.', exp: 'die größte sorge wird durch den schaden am kernkraftwerk fukushima erweckt.'\n",
      "Original 'much is only on paper and unfortunately the reality is different.', got 'leider geht es nur um die realität und die realität.', exp: 'vieles steht nur auf dem papier, die realität sieht leider anders aus.'\n",
      "Original 'this would not help anyone, neither the assistants themselves nor the members of parliament.', got 'das würde weder den europäischen parlament noch hilfe für die mitglieder des parlaments beitragen.', exp: 'damit wäre niemandem geholfen, weder den assistenten noch den abgeordneten hier im hause.'\n",
      "Original 'can civil society in russia expect nothing more than this kind of provocation?', got 'kann die zivilgesellschaft in dieser zivilisation nicht mehr erwarten?', exp: 'hat die zivilgesellschaft in russland nur provokationen zu erwarten?'\n"
     ]
    }
   ],
   "source": [
    "# Performance on validation set\n",
    "val_df = df.iloc[val_ids]\n",
    "for en, de in val_df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T11:47:32.451611Z",
     "start_time": "2018-05-25T10:45:21.851711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d33961715c4c1f92b84b048e4b6278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average BLEU on test set = 0.18274617561255022\n"
     ]
    }
   ],
   "source": [
    "bleu = bleu_scores_europarl(\n",
    "    input_texts=df.input_texts.iloc[val_ids[:TEST_SIZE]],\n",
    "    target_texts=df.target_texts.iloc[val_ids[:TEST_SIZE]],\n",
    "    predict=lambda text: predict(text)\n",
    ")\n",
    "print(f'average BLEU on test set = {bleu.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T18:17:20.995932Z",
     "start_time": "2018-05-13T18:17:20.994111Z"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The texts feel more readable, allthough the BLEU score rises up only a bit ($0.328 > $0.316$).\n",
    "A lot of the problems in the translations certainly depend on the still small training set (~200k), so as next step, I'll train on a bigger sub-corpus of longer texts. This will also make the need to use an attention model more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 294,
   "position": {
    "height": "40px",
    "left": "553px",
    "right": "192px",
    "top": "132px",
    "width": "615px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
