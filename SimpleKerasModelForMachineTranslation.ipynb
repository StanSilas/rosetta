{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple seq2seq model in keras that translates english <-> german"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step I take the model used for the [toy problem of adding/subtracting numbers](SimpleKerasModelForAddingAndSubstraction.ipynb) and train it with english/german data for machine translation.\n",
    "\n",
    "As trainings set I use the [European Parliament Proceedings Parallel Corpus 1996-2011](http://statmt.org/europarl/) German-English corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:37:58.076917Z",
     "start_time": "2018-05-09T09:37:56.732341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janek/.local/share/virtualenvs/rosetta-WKmHhL03/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# technical detail so that an instance (maybe running in a different window)\n",
    "# doesn't take all the GPU memory resulting in some strange error messages\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:37:58.355021Z",
     "start_time": "2018-05-09T09:37:58.078164Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Fixing random state ensure reproducible results\n",
    "RANDOM_STATE=42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:37:58.358653Z",
     "start_time": "2018-05-09T09:37:58.356420Z"
    }
   },
   "outputs": [],
   "source": [
    "START = '^'\n",
    "END = '\\n'\n",
    "\n",
    "MAX_INPUT_LENGTH = 35\n",
    "MAX_TARGET_LENGTH = 45\n",
    "LATENT_DIM = 512\n",
    "EMBEDDING_DIM = 64\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-08T13:03:31.674082Z",
     "start_time": "2018-05-08T13:03:31.670919Z"
    }
   },
   "source": [
    "## Download and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:37:58.366546Z",
     "start_time": "2018-05-09T09:37:58.360112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-en.tgz already downloaded (188.6 MB)\n"
     ]
    }
   ],
   "source": [
    "def download_file(fname, url):\n",
    "    print(f\"Downloading {fname} from {url} ...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    total_size = int(response.headers.get('content-length', 0)); \n",
    "    block_size = 1024\n",
    "\n",
    "    download = tqdm(\n",
    "        response.iter_content(block_size),\n",
    "        total=math.ceil(total_size // block_size),\n",
    "        unit='KB',\n",
    "        unit_scale=True\n",
    "    )\n",
    "    with open(f\"{fname}\", \"wb\") as handle:\n",
    "        for data in download:\n",
    "            handle.write(data)\n",
    "\n",
    "PATH = 'data'\n",
    "FILES = {\n",
    "    'de-en.tgz': 'http://statmt.org/europarl/v7/de-en.tgz',  # incredible: really only http, not https :-o\n",
    "}\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "\n",
    "for name, url in FILES.items():\n",
    "    fname = os.path.join(PATH, name)\n",
    "    exists = os.path.exists(fname)\n",
    "    size = os.path.getsize(fname) if exists else -1\n",
    "    if exists and size > 0:\n",
    "        print(f'{name} already downloaded ({size / 2**20:3.1f} MB)')\n",
    "        continue\n",
    "    download_file(fname, url)\n",
    "    if (fname.endswith(\".tgz\")):\n",
    "        tar = tarfile.open(fname, \"r:gz\")\n",
    "        tar.extractall(path=PATH)\n",
    "        tar.close()\n",
    "        print(f'Extracted {fname} ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:37:59.937860Z",
     "start_time": "2018-05-09T09:37:58.368120Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 60)\n",
    "df = pd.DataFrame(data={\n",
    "    'input_texts': open(f'{PATH}/europarl-v7.de-en.en', 'r').readlines(),\n",
    "    'target_texts': open(f'{PATH}/europarl-v7.de-en.de', 'r').readlines(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:01.361944Z",
     "start_time": "2018-05-09T09:37:59.940622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920209"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_texts</th>\n",
       "      <th>target_texts</th>\n",
       "      <th>input_length</th>\n",
       "      <th>target_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session\\n</td>\n",
       "      <td>^Wiederaufnahme der Sitzungsperiode\\n</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European Parliament...</td>\n",
       "      <td>^Ich erkläre die am Freitag, dem 17. Dezember unterbroch...</td>\n",
       "      <td>208</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although, as you will have seen, the dreaded 'millennium...</td>\n",
       "      <td>^Wie Sie feststellen konnten, ist der gefürchtete \"Mille...</td>\n",
       "      <td>192</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have requested a debate on this subject in the cours...</td>\n",
       "      <td>^Im Parlament besteht der Wunsch nach einer Aussprache i...</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the meantime, I should like to observe a minute' s si...</td>\n",
       "      <td>^Heute möchte ich Sie bitten - das ist auch der Wunsch e...</td>\n",
       "      <td>233</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input_texts  \\\n",
       "0                                  Resumption of the session\\n   \n",
       "1  I declare resumed the session of the European Parliament...   \n",
       "2  Although, as you will have seen, the dreaded 'millennium...   \n",
       "3  You have requested a debate on this subject in the cours...   \n",
       "4  In the meantime, I should like to observe a minute' s si...   \n",
       "\n",
       "                                                  target_texts  input_length  \\\n",
       "0                        ^Wiederaufnahme der Sitzungsperiode\\n            26   \n",
       "1  ^Ich erkläre die am Freitag, dem 17. Dezember unterbroch...           208   \n",
       "2  ^Wie Sie feststellen konnten, ist der gefürchtete \"Mille...           192   \n",
       "3  ^Im Parlament besteht der Wunsch nach einer Aussprache i...           106   \n",
       "4  ^Heute möchte ich Sie bitten - das ist auch der Wunsch e...           233   \n",
       "\n",
       "   target_length  \n",
       "0             36  \n",
       "1            220  \n",
       "2            187  \n",
       "3            112  \n",
       "4            219  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "df.target_texts = '^' + df.target_texts  # encode a start symbol (doesn't occur in texts)\n",
    "df['input_length'] = df.input_texts.apply(len)\n",
    "df['target_length'] = df.target_texts.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only use short translations right now\n",
    "\n",
    "So, first I plot sentence length on a logarithmic scale, \n",
    "then I only choose short input texts (and a bit longer target texts as german is more verbose than english)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:01.829897Z",
     "start_time": "2018-05-09T09:38:01.364540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df.input_length\n",
    "logbins = np.logspace(1,5,20)\n",
    "plt.hist(x, bins=logbins)\n",
    "plt.xscale('log')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:01.927418Z",
     "start_time": "2018-05-09T09:38:01.831388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_empty = (df.input_length > 1) & (df.target_length > 1)  # there are empty phrases like '\\n' --> 'Frau Präsidentin\\n'\n",
    "short_inputs = (df.input_length < MAX_INPUT_LENGTH) & (df.target_length < MAX_TARGET_LENGTH)\n",
    "sum(short_inputs)\n",
    "df = df[non_empty & short_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:01.935004Z",
     "start_time": "2018-05-09T09:38:01.928937Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = pd.concat([df.input_texts, df.target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:03.840386Z",
     "start_time": "2018-05-09T09:38:01.936733Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=100, filters=None, char_level=True, oov_token='~')\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "df['input_sequences'] = tokenizer.texts_to_sequences(df.input_texts)\n",
    "df['target_sequences'] = tokenizer.texts_to_sequences(df.target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:03.851366Z",
     "start_time": "2018-05-09T09:38:03.841571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 449080),\n",
       " ('e', 373783),\n",
       " ('i', 219557),\n",
       " ('s', 214808),\n",
       " ('t', 207105),\n",
       " ('n', 202687),\n",
       " ('a', 174947),\n",
       " ('r', 170955),\n",
       " ('\\n', 147498),\n",
       " ('h', 135801),\n",
       " ('o', 132216),\n",
       " ('l', 101829),\n",
       " ('.', 98218),\n",
       " ('u', 88656),\n",
       " ('d', 82701),\n",
       " ('c', 80669),\n",
       " ('^', 73749),\n",
       " ('m', 61360),\n",
       " ('g', 57526),\n",
       " ('p', 39510),\n",
       " ('b', 38849),\n",
       " ('f', 35851),\n",
       " ('w', 35250),\n",
       " ('k', 30398),\n",
       " ('D', 27645),\n",
       " ('T', 26099),\n",
       " ('y', 23141),\n",
       " ('A', 22643),\n",
       " ('W', 20261),\n",
       " ('v', 19340),\n",
       " ('\\xa0', 18843),\n",
       " ('I', 18074),\n",
       " ('(', 15780),\n",
       " (')', 15426),\n",
       " ('?', 13866),\n",
       " ('S', 13233),\n",
       " ('z', 11860),\n",
       " (',', 11591),\n",
       " ('B', 11297),\n",
       " ('E', 10436),\n",
       " ('P', 10128),\n",
       " ('H', 9664),\n",
       " ('0', 9246),\n",
       " ('ä', 9089),\n",
       " ('!', 8900),\n",
       " ('M', 8556),\n",
       " ('ü', 8353),\n",
       " ('V', 6454),\n",
       " ('-', 6413),\n",
       " ('1', 6046),\n",
       " ('F', 5660),\n",
       " ('N', 5405),\n",
       " (':', 5335),\n",
       " ('R', 4632),\n",
       " ('2', 4460),\n",
       " ('4', 4315),\n",
       " ('G', 4252),\n",
       " ('C', 4160),\n",
       " ('K', 4021),\n",
       " ('9', 3993),\n",
       " ('L', 3937),\n",
       " ('ö', 3389),\n",
       " ('j', 3199),\n",
       " ('/', 3144),\n",
       " ('U', 3018),\n",
       " ('ß', 2474),\n",
       " ('Z', 2455),\n",
       " ('5', 2391),\n",
       " ('x', 2373),\n",
       " ('O', 2369),\n",
       " ('3', 1919),\n",
       " ('q', 1491),\n",
       " ('7', 1485),\n",
       " ('8', 1444),\n",
       " ('6', 1392),\n",
       " ('–', 1256),\n",
       " ('J', 1161),\n",
       " ('Q', 1136),\n",
       " ('Y', 921),\n",
       " (\"'\", 901),\n",
       " ('\"', 553),\n",
       " ('Ä', 368),\n",
       " ('%', 179),\n",
       " ('é', 161),\n",
       " ('Ü', 147),\n",
       " ('í', 112),\n",
       " ('á', 79),\n",
       " ('’', 68),\n",
       " ('è', 60),\n",
       " ('ó', 59),\n",
       " (';', 58),\n",
       " ('X', 45),\n",
       " ('Ö', 36),\n",
       " ('“', 35),\n",
       " ('‘', 33),\n",
       " ('„', 28),\n",
       " ('°', 28),\n",
       " ('č', 21),\n",
       " ('…', 19),\n",
       " ('ç', 19),\n",
       " ('à', 18),\n",
       " ('*', 17),\n",
       " (']', 16),\n",
       " ('ò', 15),\n",
       " ('[', 15),\n",
       " ('ñ', 14),\n",
       " ('ă', 14),\n",
       " ('ł', 13),\n",
       " ('ï', 13),\n",
       " ('ã', 13),\n",
       " ('æ', 11),\n",
       " ('ń', 9),\n",
       " ('Μ', 9),\n",
       " ('ø', 8),\n",
       " ('ê', 8),\n",
       " ('Š', 8),\n",
       " ('š', 8),\n",
       " ('ô', 8),\n",
       " ('Å', 7),\n",
       " ('&', 6),\n",
       " ('¡', 6),\n",
       " ('Ţ', 5),\n",
       " ('´', 4),\n",
       " ('α', 4),\n",
       " ('ρ', 4),\n",
       " ('π', 4),\n",
       " ('ň', 4),\n",
       " ('ş', 4),\n",
       " ('”', 4),\n",
       " ('о', 4),\n",
       " ('•', 4),\n",
       " ('\\xad', 4),\n",
       " ('σ', 3),\n",
       " ('ą', 3),\n",
       " ('χ', 3),\n",
       " ('τ', 3),\n",
       " ('Α', 3),\n",
       " ('ú', 3),\n",
       " ('ι', 2),\n",
       " ('ί', 2),\n",
       " ('ε', 2),\n",
       " ('<', 2),\n",
       " ('ż', 2),\n",
       " ('ή', 2),\n",
       " ('ο', 2),\n",
       " ('ά', 2),\n",
       " ('Κ', 2),\n",
       " ('έ', 2),\n",
       " ('Υ', 2),\n",
       " ('â', 2),\n",
       " ('ž', 2),\n",
       " ('ǎ', 2),\n",
       " ('ő', 2),\n",
       " ('·', 2),\n",
       " ('ė', 2),\n",
       " ('î', 2),\n",
       " ('ý', 2),\n",
       " ('и', 2),\n",
       " ('л', 2),\n",
       " ('ш', 2),\n",
       " ('д', 2),\n",
       " ('е', 2),\n",
       " ('р', 2),\n",
       " ('б', 2),\n",
       " ('Д', 2),\n",
       " ('ţ', 2),\n",
       " ('+', 2),\n",
       " ('û', 2),\n",
       " ('Í', 2),\n",
       " ('ì', 1),\n",
       " ('ς', 1),\n",
       " ('ζ', 1),\n",
       " ('η', 1),\n",
       " ('δ', 1),\n",
       " ('ν', 1),\n",
       " ('υ', 1),\n",
       " ('‚', 1),\n",
       " ('ę', 1),\n",
       " ('`', 1),\n",
       " ('>', 1),\n",
       " ('Ο', 1),\n",
       " ('Τ', 1),\n",
       " ('Ν', 1),\n",
       " ('ī', 1),\n",
       " ('ë', 1),\n",
       " ('Ï', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(sorted(tokenizer.word_counts.items(), key=lambda d: d[1])))\n",
    "sum(1 for w, count in tokenizer.word_counts.items() if count > 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:03.868221Z",
     "start_time": "2018-05-09T09:38:03.852637Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len_input = df.input_length.max()\n",
    "max_len_target = df.target_length.max()\n",
    "nr_tokens = len(tokenizer.word_index) + 1  # add 0 padding not in word_index contained\n",
    "\n",
    "# one hot encoded y_t_output wouldn't fit into memory any longer\n",
    "# so need to train/validate on batches generated on the fly\n",
    "def create_batch_generator(samples_ids):\n",
    "    \n",
    "    def batch_generator():\n",
    "        nr_batches = np.ceil(len(samples_ids) / BATCH_SIZE)\n",
    "        while True:\n",
    "            shuffled_ids = np.random.permutation(samples_ids)\n",
    "            batch_splits = np.array_split(shuffled_ids, nr_batches)\n",
    "            for batch_ids in batch_splits:\n",
    "                batch_X = pad_sequences(df.iloc[batch_ids].input_sequences, padding='post', maxlen=max_len_input)\n",
    "                batch_y = pad_sequences(df.iloc[batch_ids].target_sequences, padding='post', maxlen=max_len_target)\n",
    "                batch_y_t_output = keras.utils.to_categorical(batch_y[:,1:], num_classes=len(tokenizer.word_index)+1)\n",
    "                batch_x_t_input = batch_y[:,:-1]\n",
    "                yield ([batch_X, batch_x_t_input], batch_y_t_output)\n",
    "    \n",
    "    return batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:03.874151Z",
     "start_time": "2018-05-09T09:38:03.869620Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(np.arange(df.shape[0]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:03.881319Z",
     "start_time": "2018-05-09T09:38:03.876200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(66374, 7375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_tokens\n",
    "len(tokenizer.word_index)\n",
    "len(train_ids), len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:05.070828Z",
     "start_time": "2018-05-09T09:38:03.882912Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_gru = L.Bidirectional(\n",
    "    L.GRU(LATENT_DIM // 2, dropout=DROPOUT, return_state=True, name='encoder_gru'),\n",
    "    name='encoder_bidirectional'\n",
    ")\n",
    "decoder_gru = L.GRU(LATENT_DIM, dropout=DROPOUT, return_sequences=True, return_state=True, name='decoder_gru')\n",
    "decoder_dense = L.Dense(nr_tokens, activation='softmax', name='decoder_outputs')\n",
    "\n",
    "shared_embedding = L.Embedding(nr_tokens, EMBEDDING_DIM, mask_zero=True, name='shared_embedding')\n",
    "\n",
    "encoder_inputs = L.Input(shape=(max_len_input, ), dtype='int32', name='encoder_inputs')\n",
    "encoder_embeddings = shared_embedding(encoder_inputs)\n",
    "_, encoder_state_1, encoder_state_2 = encoder_gru(encoder_embeddings)\n",
    "encoder_states = L.concatenate([encoder_state_1, encoder_state_2])\n",
    "\n",
    "decoder_inputs = L.Input(shape=(max_len_target-1, ), dtype='int32', name='decoder_inputs')\n",
    "decoder_mask = L.Masking(mask_value=0)(decoder_inputs)\n",
    "decoder_embeddings_inputs = shared_embedding(decoder_mask)\n",
    "decoder_embeddings_outputs, _ = decoder_gru(decoder_embeddings_inputs, initial_state=encoder_states) \n",
    "decoder_outputs = decoder_dense(decoder_embeddings_outputs)\n",
    "\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)\n",
    "\n",
    "inference_encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "inference_decoder_state_inputs = L.Input(shape=(LATENT_DIM, ), dtype='float32', name='inference_decoder_state_inputs')\n",
    "inference_decoder_embeddings_outputs, inference_decoder_states = decoder_gru(\n",
    "    decoder_embeddings_inputs, initial_state=inference_decoder_state_inputs\n",
    ")\n",
    "inference_decoder_outputs = decoder_dense(inference_decoder_embeddings_outputs)\n",
    "\n",
    "inference_decoder_model = Model(\n",
    "    [decoder_inputs, inference_decoder_state_inputs], \n",
    "    [inference_decoder_outputs, inference_decoder_states]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:05.076357Z",
     "start_time": "2018-05-09T09:38:05.072025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 43)           0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_inputs (InputLayer)     (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             12032       encoder_inputs[0][0]             \n",
      "                                                                 masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bidirectional (Bidirect [(None, 512), (None, 493056      shared_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           encoder_bidirectional[0][1]      \n",
      "                                                                 encoder_bidirectional[0][2]      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 43, 512), (N 886272      shared_embedding[1][0]           \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 43, 188)      96444       decoder_gru[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,487,804\n",
      "Trainable params: 1,487,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_inputs (InputLayer)     (None, 43)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 43)           0           decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared_embedding (Embedding)    multiple             12032       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inference_decoder_state_inputs  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_gru (GRU)               [(None, 43, 512), (N 886272      shared_embedding[1][0]           \n",
      "                                                                 inference_decoder_state_inputs[0]\n",
      "__________________________________________________________________________________________________\n",
      "decoder_outputs (Dense)         (None, 43, 188)      96444       decoder_gru[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 994,748\n",
      "Trainable params: 994,748\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "inference_decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:38:05.110499Z",
     "start_time": "2018-05-09T09:38:05.078315Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(clipnorm=1.), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:19.266596Z",
     "start_time": "2018-05-09T09:38:05.111866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "519/519 [==============================] - 50s 97ms/step - loss: 1.9321 - val_loss: 1.2174\n",
      "Epoch 2/20\n",
      "519/519 [==============================] - 51s 98ms/step - loss: 1.0898 - val_loss: 0.9307\n",
      "Epoch 3/20\n",
      "519/519 [==============================] - 50s 97ms/step - loss: 0.9039 - val_loss: 0.8104\n",
      "Epoch 4/20\n",
      "519/519 [==============================] - 51s 97ms/step - loss: 0.8119 - val_loss: 0.7505\n",
      "Epoch 5/20\n",
      "519/519 [==============================] - 54s 103ms/step - loss: 0.7539 - val_loss: 0.7226\n",
      "Epoch 6/20\n",
      "519/519 [==============================] - 48s 92ms/step - loss: 0.7107 - val_loss: 0.6831\n",
      "Epoch 7/20\n",
      "519/519 [==============================] - 48s 92ms/step - loss: 0.6773 - val_loss: 0.6629\n",
      "Epoch 8/20\n",
      "519/519 [==============================] - 50s 95ms/step - loss: 0.6510 - val_loss: 0.6498\n",
      "Epoch 9/20\n",
      "519/519 [==============================] - 50s 96ms/step - loss: 0.6293 - val_loss: 0.6302\n",
      "Epoch 10/20\n",
      "519/519 [==============================] - 48s 92ms/step - loss: 0.6107 - val_loss: 0.6232\n",
      "Epoch 11/20\n",
      "519/519 [==============================] - 47s 91ms/step - loss: 0.5945 - val_loss: 0.6096\n",
      "Epoch 12/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5800 - val_loss: 0.6087\n",
      "Epoch 13/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5684 - val_loss: 0.6016\n",
      "Epoch 14/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5578 - val_loss: 0.5920\n",
      "Epoch 15/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5463 - val_loss: 0.5900\n",
      "Epoch 16/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5378 - val_loss: 0.5844\n",
      "Epoch 17/20\n",
      "519/519 [==============================] - 47s 90ms/step - loss: 0.5296 - val_loss: 0.5939\n",
      "Epoch 18/20\n",
      "519/519 [==============================] - 49s 94ms/step - loss: 0.5216 - val_loss: 0.5849\n",
      "Epoch 19/20\n",
      "519/519 [==============================] - 48s 92ms/step - loss: 0.5153 - val_loss: 0.5887\n",
      "Epoch 20/20\n",
      "519/519 [==============================] - 50s 97ms/step - loss: 0.5072 - val_loss: 0.5751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efa4dcfa8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = create_batch_generator(train_ids)\n",
    "val_generator = create_batch_generator(val_ids)\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=np.ceil(len(train_ids) / BATCH_SIZE),\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=np.ceil(len(val_ids) / BATCH_SIZE),\n",
    ")\n",
    "#model.fit([X, x_t_input], y_t_output, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:19.279371Z",
     "start_time": "2018-05-09T09:54:19.270033Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = inference_encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, max_len_target-1))\n",
    "    target_seq[0, 0] = tokenizer.word_index[START]\n",
    "    \n",
    "    tokens = {idx: token for (token, idx) in tokenizer.word_index.items()}\n",
    "    \n",
    "    decoded_sequence = ''\n",
    "    for i in range(max_len_target):\n",
    "        output_tokens, output_states = inference_decoder_model.predict(\n",
    "            [target_seq, states_value]\n",
    "        )\n",
    "        \n",
    "        # greedy search\n",
    "        sampled_token_idx = np.argmax(output_tokens[0, 0, :])\n",
    "        sampled_token = tokens.get(sampled_token_idx, '.')\n",
    "        if sampled_token == END:\n",
    "            break\n",
    "        decoded_sequence += sampled_token\n",
    "            \n",
    "        target_seq[0, 0] = sampled_token_idx\n",
    "        states_value = output_states\n",
    "    \n",
    "    return decoded_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:19.292112Z",
     "start_time": "2018-05-09T09:54:19.282820Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    return decode_sequence(keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenizer.texts_to_sequences([sentence]),\n",
    "        padding='post',\n",
    "        maxlen=max_len_input,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T10:02:42.529487Z",
     "start_time": "2018-05-09T10:02:38.891203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello.\\n' --> 'Heine Ziele.'\n",
      "'You are welcome.\\n' --> 'Sie haben das Wort.'\n",
      "'How do you do?\\n' --> 'Was können Sie damit umgehen?'\n",
      "'I hate mondays.\\n' --> 'Ich möchte noch viel Geld eingehen.'\n",
      "'I am a programmer.\\n' --> 'Ich bin für eine Meinung.'\n",
      "'Data is the new oil.\\n' --> 'Gar ist ein letztes Beispiel.'\n",
      "'It could be worse.\\n' --> 'Das kann man aufhören.'\n",
      "'I am on top of it.\\n' --> 'Ich bin mir das wirklich bekannt.'\n",
      "'N° Uno\\n' --> 'und Jeu)'\n",
      "'Awesome!\\n' --> 'Eines Mumination!'\n",
      "'Put your feet up!\\n' --> 'Aber auch das ist unsere Aufgabe!'\n",
      "'From the start till the end!\\n' --> 'Freitag gibt es sich nicht die Neute!'\n",
      "'From dusk till dawn.\\n' --> 'Went jetzt noch zwei Dinge.'\n"
     ]
    }
   ],
   "source": [
    "# Performance on some examples:\n",
    "EXAMPLES = [\n",
    "    'Hello.',\n",
    "    'You are welcome.',\n",
    "    'How do you do?',\n",
    "    'I hate mondays.',\n",
    "    'I am a programmer.',\n",
    "    'Data is the new oil.',\n",
    "    'It could be worse.',\n",
    "    \"I am on top of it.\",\n",
    "    \"N° Uno\",\n",
    "    \"Awesome!\",\n",
    "    \"Put your feet up!\",\n",
    "    \"From the start till the end!\",\n",
    "    \"From dusk till dawn.\",\n",
    "]\n",
    "for en in [sentence + '\\n' for sentence in EXAMPLES]:\n",
    "    print(f\"{en!r} --> {predict(en)!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:26.305798Z",
     "start_time": "2018-05-09T09:54:23.292284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'Resumption of the session\\n', got 'Wiederaufnahme der Sitzungsperiode', exp: 'Wiederaufnahme der Sitzungsperiode\\n'\n",
      "Original 'We do not know what is happening.\\n', got 'Wir wissen nicht, was das geschieht.', exp: 'Wir wissen nicht, was passiert.\\n'\n",
      "Original 'Agenda\\n', got 'Tagesordnung', exp: 'Arbeitsplan\\n'\n",
      "Original 'Relating to Wednesday:\\n', got 'Zum Dienstag:', exp: 'Zum Mittwoch:\\n'\n",
      "Original '(Applause from the PSE Group)\\n', got '(Beifall von der PPE-DE-Fraktion)', exp: '(Beifall der PSE-Fraktion)\\n'\n",
      "Original 'We then put it to a vote.\\n', got 'Wir kommen nun zur Abstimmung.', exp: 'Wir haben dann abgestimmt.\\n'\n",
      "Original 'There was a vote on this matter.\\n', got 'Es war ein sehr guter Bericht.', exp: 'Es gab eine Abstimmung zu diesem Punkt.\\n'\n",
      "Original 'That was the decision.\\n', got 'Das ist die Realität.', exp: 'Das war der Beschluß.\\n'\n",
      "Original 'There is no such document!\\n', got 'Es gibt keine Solidarität!', exp: 'Ein solches Dokument gibt es nicht!\\n'\n",
      "Original 'We have agreed to this.\\n', got 'Damit müssen wir uns alle einigen.', exp: 'Wir haben dem zugestimmt.\\n'\n"
     ]
    }
   ],
   "source": [
    "# Performance on training set:\n",
    "for en, de in df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de[1:]!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T10:01:43.088161Z",
     "start_time": "2018-05-09T10:01:37.579034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original '(Laughter and applause)\\n', got '(Heiterkeit und Beifall)', exp: '(Heiterkeit und Beifall)\\n'\n",
      "Original 'Thank, Mr Brok.\\n', got 'Vielen Dank, Herr Martin.', exp: 'Danke, Herr Brok.\\n'\n",
      "Original '\\xa0\\xa0 .\\n', got '\\xa0\\xa0 .', exp: '\\xa0\\xa0 Herr Präsident, meine Damen und Herren!\\n'\n",
      "Original 'It is madness!\\n', got 'Das ist eine Schande!', exp: 'Das ist Wahnsinn!\\n'\n",
      "Original '(HU) Thank you, Mr President.\\n', got '(HU) Vielen Dank, Herr Präsident!', exp: '(HU) Vielen Dank, Herr Präsident!\\n'\n",
      "Original 'I voted in favour of this report.\\n', got 'Ich habe für diesen Bericht gestimmt.', exp: 'Ich habe für diesen Bericht gestimmt.\\n'\n",
      "Original '.\\n', got '.', exp: '.\\n'\n",
      "Original 'Only China has benefited from it.\\n', got 'Nur das Geld wird das Geld genau gesagt.', exp: 'Profitiert hat davon lediglich China.\\n'\n",
      "Original 'Mr Rothley did that.\\n', got 'Herr Watson.', exp: 'Herr Rothley hat es geschafft.\\n'\n",
      "Original 'Just as Mr Cashman said:\\n', got 'Nur einen Fortschrittsbericht (Fortsetzung)', exp: 'Genauso wie Herr Cashman sagte:\\n'\n",
      "Original 'Azzolini report (A4-0252/97)\\n', got 'Bericht Angtolo (A4-0333/98)', exp: 'Bericht Azzolini (A4-0252/97)\\n'\n",
      "Original 'Farassino report\\n', got 'Zum Bericht Chastina', exp: 'Zum Bericht Farassino\\n'\n",
      "Original '\\xa0\\xa0 That point is noted.\\n', got '\\xa0\\xa0 Die Aussprache ist geschlossen.', exp: '\\xa0\\xa0 Dieser Punkt ist notiert.\\n'\n",
      "Original 'on the situation in Nepal.\\n', got 'zum Schluss der Kommission.', exp: 'zur Lage in Nepal.\\n'\n",
      "Original 'We know this is not enough.\\n', got 'Wir können das nicht vergessen.', exp: 'Wir wissen, dass dies nicht ausreicht.\\n'\n",
      "Original 'There are the new minefields.\\n', got 'Es gibt noch einen die nicht der Fall.', exp: 'Neue Minenfelder.\\n'\n",
      "Original 'Hieronymi Report (A5-0186/2000)\\n', got 'Bericht Hirtrond (A5-0369/2001)', exp: 'Bericht Hieronymi (A5-0186/2000)\\n'\n",
      "Original 'Provocation.\\n', got 'Fakten Sind.', exp: 'Das war eine Provokation.\\n'\n",
      "Original 'That is not the intention.\\n', got 'Das ist nicht der richtige Weg.', exp: 'Das war nicht die Absicht.\\n'\n"
     ]
    }
   ],
   "source": [
    "val_df = df.iloc[val_ids]\n",
    "for en, de in val_df[['input_texts', 'target_texts']][1:20].values.tolist():\n",
    "    print(f\"Original {en!r}, got {predict(en)!r}, exp: {de[1:]!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:26.321739Z",
     "start_time": "2018-05-09T09:54:26.317403Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Mean average error on a test set\n",
    "# test_df = create_equations_df(size=1000)\n",
    "# test_df['y_pred'] = test_df.input_texts.apply(predict).astype(int)\n",
    "# test_df['y_true'] = test_df.result\n",
    "# print(\"MAE\", np.mean(np.abs(test_df.y_pred - test_df.y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-09T09:54:26.327221Z",
     "start_time": "2018-05-09T09:54:26.323065Z"
    }
   },
   "outputs": [],
   "source": [
    "## Conclusion\n",
    "\n",
    "# It doesn't work perfect, but fine enough to show that seq2seq works in some way. I wouldn't be surprised if the mean average error is better than average human bias for calculating without any tools.\n",
    "# For improvements and further discussions I'll move to a real problem (translating) and main steps will be:\n",
    "# * Bytepairencoding/Word embeddings\n",
    "# * Beam Search\n",
    "# * Attention models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 301,
   "position": {
    "height": "40px",
    "left": "987px",
    "right": "23px",
    "top": "124px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
